[
  {
    "objectID": "sleep_plots.html",
    "href": "sleep_plots.html",
    "title": "Sleep plots",
    "section": "",
    "text": "source\n\nget_channels_colors\n\n get_channels_colors (channels:pandas.core.frame.DataFrame,\n                      events:pandas.core.frame.DataFrame,\n                      participant_id:int=None, array_index:int=None,\n                      time_range:Tuple[str,str]=None,\n                      event_filter:Iterable[str]=None,\n                      palette:str='muted')\n\n\nsource\n\n\nplot_sleep_channels\n\n plot_sleep_channels (channels:pandas.core.frame.DataFrame,\n                      x:str='collection_timestamp', y:str='values',\n                      row:str='source', hue:str='channel_group',\n                      participant_id:int=None, array_index:int=None,\n                      time_range:Tuple[str,str]=None,\n                      y_include:Iterable[str]=None,\n                      y_exclude:Iterable[str]=None,\n                      rename_channels:dict={'actigraph': 'Actigraph',\n                      'body_position': 'Body Position', 'heart_rate':\n                      'Heart Rate', 'heart_rate_raw': 'Heart Rate Raw',\n                      'pat_infra': 'PAT Infra', 'pat_amplitude': 'PAT\n                      Amplitude', 'pat_lpf': 'PAT LPF',\n                      'respiratory_movement': 'Respiratory Mov.', 'spo2':\n                      'SpO2', 'snore_db': 'Snore dB', 'pat_view': 'PAT\n                      View', 'sleep_stage': 'Sleep Stage'},\n                      discrete_events:Iterable[str]=['sleep_stage',\n                      'body_position'], resample:str='1s',\n                      color_map:pandas.core.series.Series=None,\n                      palette:str='muted', fig:pheno_utils.timeseries_plot\n                      s.TimeSeriesFigure=None,\n                      ax:List[matplotlib.axes._axes.Axes]=None, height=1,\n                      **kwargs)\n\nplot channels data for a given participant and array_index\n\nsource\n\n\nplot_sleep\n\n plot_sleep (events:pandas.core.frame.DataFrame,\n             channels:pandas.core.frame.DataFrame,\n             participant_id:int=None, array_index:int=None,\n             time_range:Tuple[str,str]=None,\n             event_filter:Iterable[str]=None,\n             channel_filter:Iterable[str]=['actigraph', 'pat_infra',\n             'body_position', 'snore_db', 'heart_rate', 'spo2'],\n             event_height:float=1, channel_height:float=0.5,\n             padding:float=-0.02, figsize:Tuple[float,float]=None,\n             palette:str='muted')\n\n*Plot sleep events and channels data.\nArgs:\nevents (pd.DataFrame): The sleep events dataframe.\nchannels (pd.DataFrame): The sleep channels dataframe.\nparticipant_id (int): The participant id to filter the data.\narray_index (int): The array index to filter the data.\ntime_range (Tuple[str, str]): The time range to filter the data.\nevent_filter (Iterable[str]): The events to include in the plot.\nchannel_filter (Iterable[str]): The channels to include in the plot.\nevent_height (float): The relative height of the events subplot.\nchannel_height (float): The relative height of each channel's subplot.\npadding (float): The padding between subplots.\nfigsize (Tuple[float, float]): The size of the figure.\npalette (str): The color palette to use.\nReturns:\nTimeSeriesFigure: The figure with the sleep events and channels data.*\n\nsource\n\n\nget_sleep_period\n\n get_sleep_period (events:pandas.core.frame.DataFrame)\n\n*Get the sleep period from the sleep events dataframe.\nArgs:\nevents (pd.DataFrame): The sleep events dataframe.\nReturns:\npd.DataFrame: The sleep period dataframe.*\n\n\nHow to plot sleep events and channels\nThis module provides functions for plotting sleep events and channels data.\nFirst, we will load time series DFs from the sleep monitoring dataset.\n\nfrom pheno_utils import PhenoLoader\n\npl = PhenoLoader('sleep')\nchannels_df = pl.load_bulk_data('channels_time_series')  # contains: heart_rate, spo2, respiratory_movement\nevents_df = pl.load_bulk_data('events_time_series')\n\n/home/ec2-user/projects/pheno-utils/pheno_utils/pheno_loader.py:610: UserWarning: No date field found\n  warnings.warn(f'No date field found')\n\n\n\nchannels_df.head(5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nvalues\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\ncollection_timestamp\nsource\n\n\n\n\n\n0\n10k\n00_00_visit\n1\n2020-06-23 00:40:29+03:00\nheart_rate\n62.0\n\n\nrespiratory_movement\n0.0\n\n\nspo2\nNaN\n\n\n2020-06-23 00:40:29.200000+03:00\nrespiratory_movement\n0.0\n\n\n2020-06-23 00:40:29.400000+03:00\nrespiratory_movement\n0.0\n\n\n\n\n\n\n\n\nevents_df.head(5)\n\n\n\n\n\n\n\n\n\n\n\n\nevent_end\nevent\nchannel\nstart\nend\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\ncollection_timestamp\n\n\n\n\n\n\n\n\n\n0\n10k\n00_00_visit\n1\n2020-06-23 00:40:29+03:00\n2020-06-23 00:40:34+03:00\nExcluded\nheart_rate_raw\n0\n5\n\n\n2020-06-23 00:40:29+03:00\n2020-06-23 00:40:34+03:00\nExcluded\nspo2\n0\n5\n\n\n2020-06-23 00:40:29+03:00\n2020-06-23 00:55:29+03:00\nWake\nactigraph\n0\n900\n\n\n2020-06-23 00:40:29+03:00\n2020-06-23 00:40:34+03:00\nInvalid Time\ngeneral\n0\n5\n\n\n2020-06-23 00:40:29+03:00\n2020-06-23 00:40:32+03:00\nArtifact\npat_infra\n0\n3\n\n\n\n\n\n\n\n\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nplot_sleep(events_df, channels_df,\n           channel_filter=['heart_rate', 'spo2', 'respiratory_movement'],\n           figsize=(8, 8), padding=0.03)",
    "crumbs": [
      "Plots",
      "Sleep plots"
    ]
  },
  {
    "objectID": "basic_analysis.html",
    "href": "basic_analysis.html",
    "title": "Basic analysis",
    "section": "",
    "text": "source\n\ncustom_describe\n\n custom_describe (df:pandas.core.frame.DataFrame)\n\n*Generates a custom summary statistics dataframe for mixed data types.\nArgs: df: The input pandas DataFrame\nReturns: A pandas DataFrame containing the summary statistics*\n\ndata = generate_synthetic_data(n=100)\n\ncustom_describe(data[[\"date_of_research_stage\", \"sex\", \"val2\"]])\n\n\n\n\n\n\n\n\ndate_of_research_stage\nsex\nval2\n\n\n\n\ncount\n100\n100.0\n100.0\n\n\nunique\n99\n2.0\n100.0\n\n\nmost_frequent\nNaN\n0.0\n-3.137486\n\n\nmin\n2020-01-04 00:00:00\n0.0\n-3.137486\n\n\nmax\n2023-06-25 00:00:00\n1.0\n41.432775\n\n\nmean\nNaN\n0.46\n19.091836\n\n\nmedian\nNaN\n0.0\n19.601733\n\n\nstd\nNaN\n0.500908\n10.401328\n\n\n\n\n\n\n\n\nsource\n\n\nassign_nearest_research_stage\n\n assign_nearest_research_stage (dataset:pandas.core.frame.DataFrame,\n                                population:pandas.core.frame.DataFrame,\n                                max_days:int=60,\n                                stages:List[str]=['visit'],\n                                agg:Optional[str]='first')\n\n*Assign the nearest research stage to each record in a dataset.\nArgs: dataset (pd.DataFrame): The dataset containing records to be assigned research stages. population (pd.DataFrame): The population data with participant_id, cohort, research_stage, and research_stage_date. max_days (int, optional): The maximum number of days allowed between the collection date and research stage date. Defaults to 60. stages (List[str], optional): The list of types of research stages to consider. Defaults to [‘visit’]. agg (Union[str, None], optional): The aggregation function to be used when (optionally) aggregating multiple rows from the same research stage. The rows are already sorted by distance from the date of the research stage. Can be ‘first’ (closest), ‘last’ (farthest), ‘mean’, ‘min’, ‘max’, or None. Defaults to ‘first’.\nReturns: pd.DataFrame: The dataset with the nearest research stage assigned to each record.*",
    "crumbs": [
      "Analysis",
      "Basic analysis"
    ]
  },
  {
    "objectID": "blandaltman_plots.html",
    "href": "blandaltman_plots.html",
    "title": "Bland-Altman plots",
    "section": "",
    "text": "source\n\nbland_altman_triple_plot\n\n bland_altman_triple_plot (data:pandas.core.frame.DataFrame, m1_col:str,\n                           m2_col:str, feature_str:str='',\n                           scale:str='linear')\n\n*Generates a triple plot consisting of a scatter correlation plot, Bland-Altman plot, and a percentage Bland-Altman plot.\nArgs: data (pd.DataFrame): A pandas DataFrame containing the data. m1_col (str): The name of the first measurement column in the DataFrame. m2_col (str): The name of the second measurement column in the DataFrame. feature_str (str, optional): A string to include in the title of the plots. Defaults to ““. scale (str, optional): The scale of the axes. Defaults to”linear”.\nReturns: None*\n\ndata = generate_synthetic_data(n=1000)\n\nbland_altman_triple_plot(data=data, m1_col=\"val1\",m2_col=\"val2\")",
    "crumbs": [
      "Plots",
      "Bland-Altman plots"
    ]
  },
  {
    "objectID": "config.html",
    "href": "config.html",
    "title": "Config",
    "section": "",
    "text": "source\n\nget_dictionary_properties_file_path\n\n get_dictionary_properties_file_path ()\n\n*Get the file path for dictionary properties - TODO: move to config file or DB. At this point only includes field_type properties.\nArgs:\nReturns: str: the path to the file*\n\nsource\n\n\nget_data_coding_file_path\n\n get_data_coding_file_path ()\n\n*Get the file path for dictionary properties - TODO: move to config file or DB. At this point only includes field_type properties.\nArgs:\nReturns: str: the path to the file*\n\nsource\n\n\ngenerate_synthetic_data\n\n generate_synthetic_data (n:int=1000)\n\n*Generates a sample DataFrame containing age, gender, and value data.\nArgs: n: The number of rows in the generated DataFrame.\nReturns: A pandas DataFrame with columns ‘age’, ‘gender’, and ‘val’.*\n\nsource\n\n\ngenerate_synthetic_data_like\n\n generate_synthetic_data_like (df:pandas.core.frame.DataFrame, n:int=1000,\n                               random_seed:int=42)\n\n*Generate a sample DataFrame containing the same columns as df, but with random data.\nArgs:\ndf: The DataFrame whose columns should be used.\nn: The number of rows in the generated DataFrame.\nReturns: A pandas DataFrame with the same columns as df.*\n\nsource\n\n\ngenerate_categorical_synthetic_data\n\n generate_categorical_synthetic_data (n:int=1000)\n\n*Generates a sample DataFrame containing age, gender, and categorical value data.\nArgs: n: The number of rows in the generated DataFrame.\nReturns: A pandas DataFrame with columns ‘age’, ‘gender’, and ‘val1’.*\n\ndata = generate_synthetic_data()\ndata.head()\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2020-11-16\n54.422828\n1\n103.721478\n48.846734\n\n\n1\n2021-06-08\n65.232948\n0\n129.512280\n54.583974\n\n\n2\n2020-08-16\n42.413863\n1\n114.878851\n52.193946\n\n\n3\n2021-04-13\n57.872618\n1\n113.653117\n51.826225\n\n\n4\n2023-07-17\n70.640233\n1\n129.669937\n56.631272\n\n\n\n\n\n\n\n\ngenerate_synthetic_data_like(data.head(), n=5)\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2020-08-16\n57.872618\n1\n113.653117\n48.846734\n\n\n1\n2021-04-13\n65.232948\n1\n103.721478\n56.631272\n\n\n2\n2023-07-17\n42.413863\n1\n129.669937\n54.583974\n\n\n3\n2021-06-08\n54.422828\n0\n114.878851\n52.193946\n\n\n4\n2020-11-16\n70.640233\n1\n129.512280\n51.826225\n\n\n\n\n\n\n\n\ndata = generate_categorical_synthetic_data()\ndata.head()\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2021-09-24\n69.788555\n1\nE\nA\n\n\n1\n2021-03-02\n36.289947\n1\nC\nB\n\n\n2\n2022-06-15\n61.501970\n1\nC\nC\n\n\n3\n2020-07-23\n46.299262\n0\nB\nA\n\n\n4\n2021-03-03\n70.127055\n1\nB\nC",
    "crumbs": [
      "Other",
      "Config"
    ]
  },
  {
    "objectID": "diet_plots.html",
    "href": "diet_plots.html",
    "title": "Diet logging plots",
    "section": "",
    "text": "source\n\ndraw_pie_chart\n\n draw_pie_chart (ax:matplotlib.axes._axes.Axes, x:float, y:float,\n                 data:List[float], size:float, palette:str='muted',\n                 alpha:float=0.7)\n\n*Draw a pie chart as an inset (in absolute figure coordinates) within the given axes at the specified data coordinates. What this solves is the issue of y-axis and x-axis scaling being different, which distorts the pie chart when drawn directly on the axes.\nArgs:\nax (plt.Axes): The axis on which to draw the pie chart.\nx (float): The x-coordinate in data coordinates where the pie chart's center will be placed.\ny (float): The y-coordinate in data coordinates where the pie chart's center will be placed.\ndata (List[float]): The data values to be represented in the pie chart.\nsize (float): The size (radius) of the pie chart in axes-relative coordinates.\npalette (str): The color palette to use for the pie slices.\nReturns:\nList[plt.Patch]: A list of wedge objects representing the pie chart slices.*\n\nsource\n\n\nextract_units\n\n extract_units (column_names:List[str])\n\n\nsource\n\n\nprepare_meals\n\n prepare_meals (diet_log:pandas.core.frame.DataFrame,\n                participant_id:int=None, array_index:int=None,\n                time_range:Tuple[str,str]=None,\n                label:str='short_food_name', return_meals:bool=True,\n                return_summary:bool=False, y_include:List[str]=None,\n                y_exclude:List[str]=None, agg_units:dict={'kcal': 'sum',\n                'g': 'sum', 'mg': 'sum', 'unknown': 'first'},\n                x_col:str='collection_timestamp')\n\n*Prepare the diet log data for plotting meals and/or daily summaries.\nArgs:\ndiet_log (pd.DataFrame): The dataframe containing the diet log data, with columns for timestamps, nutrients, and other measurements.\nparticipant_id (Optional[int]): The participant's ID to filter the diet log. If None, no filtering is done. Default is None.\narray_index (Optional[int]): The array index to filter the diet log. If None, no filtering is done. Default is None.\ntime_range (Optional[Tuple[str, str]]): A tuple of strings representing the start and end dates for filtering the data. Format should be 'YYYY-MM-DD'. Default is None.\nlabel (str): The name of the column in `diet_log` representing the labels for each meal. Default is 'short_food_name'.\nreturn_meals (bool): If True, includes individual meals in the plot. Default is True.\nreturn_summary (bool): If True, includes a daily summary in the plot. Default is False.\ny_include (List[str]): A list of nutrients (regex) to include in the plot. Default is None.\ny_exclude (List[str]): A list of nutrients (regex) to exclude from the plot. Default is None.\nagg_units (dict): A dictionary mapping nutrient units to aggregation functions.\nx_col (str): The name of the column in `diet_log` representing the x-axis variable, such as timestamps. Default is 'collection_timestamp'.\nReturns:\npd.DataFrame: A dataframe containing the prepared data for plotting.*\n\nsource\n\n\nplot_nutrient_lollipop\n\n plot_nutrient_lollipop (diet_log:pandas.core.frame.DataFrame,\n                         x:str='collection_timestamp',\n                         y:str='calories_kcal', size:str='total_g',\n                         label:str='short_food_name',\n                         participant_id:int=None, array_index:int=None,\n                         time_range:Tuple[str,str]=None, meals:bool=True,\n                         summary:bool=False, nut_include:List[str]=None,\n                         nut_exclude:List[str]=None, legend:bool=True,\n                         size_scale:float=5, palette:str='muted',\n                         alpha:float=0.7,\n                         ax:matplotlib.axes._axes.Axes=None,\n                         figsize:Tuple[float,float]=(12, 3))\n\n*Plot a lollipop chart with pie charts representing nutrient composition for each meal.\nNOTE: The y-axis is scaled to match the units of the x-axis, to avoid distortion of the pie charts. Due to scaling, if you intend to change xlim after plotting, you must also provide date_range. Use the second_y of g.plot() option to plot it with other y-axis data.\nArgs:\ndiet_log (pd.DataFrame): The dataframe containing the diet log data, with columns for timestamps, nutrients, and other measurements.\nx (str): The name of the column in `diet_log` representing the x-axis variable, such as timestamps. Default is 'collection_timestamp'.\ny (str): The name of the column in `diet_log` representing the y-axis variable, such as calories. Default is 'calories_kcal'.\nsize (str): The name of the column in `diet_log` representing the size of the pie charts. Default is 'total_g'.\nlabel (str): The name of the column in `diet_log` representing the labels for each meal. Default is 'short_food_name'.\nparticipant_id (Optional[int]): The participant's ID to filter the diet log. If None, no filtering is done. Default is None.\ntime_range (Optional[Tuple[str, str]]): A tuple of strings representing the start and end dates for filtering the data. Format should be 'YYYY-MM-DD'. Default is None.\nmeals (bool): If True, includes individual meals in the plot. Default is True.\nsummary (bool): If True, includes a daily summary in the plot. Default is False.\nnut_include (List[str]): A list of nutrients to include in the plot. Default is None.\nnut_exclude (List[str]): A list of nutrients to exclude from the plot. Default is None.\nlegend (bool): If True, includes a legend in the plot. Default is True.\nsize_scale (float): The scaling factor for the size of the pie charts. Default is 5.\npalette (str): The color palette to use for the pie slices. Default is DEFAULT_PALETTTE.\nalpha (float): The transparency of the pie slices. Default is 0.7.\nax (Optional[plt.Axes]): The Matplotlib axis on which to plot the lollipop chart. If None, a new axis is created. Default is None.\nfigsize (Tuple[float, float]): The size of the figure to create. Default is (12, 6).\nReturns:\nplt.Axes: The Matplotlib axis on which the chart was plotted.*\n\nsource\n\n\nplot_nutrient_bars\n\n plot_nutrient_bars (diet_log:pandas.core.frame.DataFrame,\n                     x:str='collection_timestamp',\n                     label:str='short_food_name', participant_id:int=None,\n                     array_index:int=None, time_range:Tuple[str,str]=None,\n                     meals:bool=True, summary:bool=False,\n                     nut_include:List[str]=None,\n                     nut_exclude:List[str]=None, agg_units:dict={'kcal':\n                     'sum', 'g': 'sum', 'mg': 'sum'}, legend:bool=True,\n                     bar_width=numpy.timedelta64(15,'m'),\n                     palette:str='muted', alpha:float=0.7,\n                     ax:matplotlib.axes._axes.Axes=None,\n                     figsize:Tuple[float,float]=(14, 3))\n\n*Plot a stacked bar chart representing nutrient intake for each meal over time.\nArgs:\ndiet_log (pd.DataFrame): The dataframe containing the diet log data, with columns for timestamps, nutrients, and other measurements.\nx (str): The name of the column in `diet_log` representing the x-axis variable, such as timestamps. Default is 'collection_timestamp'.\nlabel (str): The name of the column in `diet_log` representing the labels for each meal. Default is 'short_food_name'.\nparticipant_id (Optional[int]): The participant's ID to filter the diet log. If None, no filtering is done. Default is None.\narray_index (Optional[int]): The array index to filter the diet log. If None, no filtering is done. Default is None.\ntime_range (Optional[Tuple[str, str]]): A tuple of strings representing the start and end dates for filtering the data. Format should be 'YYYY-MM-DD'. Default is None.\nmeals (bool): If True, includes individual meals in the plot. Default is True.\nsummary (bool): If True, includes a daily summary in the plot. Default is False.\nnut_include (List[str]): A list of nutrients to include in the plot. Default is None.\nnut_exclude (List[str]): A list of nutrients to exclude from the plot. Default is None.\nagg_units (dict): A dictionary mapping nutrient units to aggregation functions. Only nutrients with units in this dictionary are plotted.\nlegend (bool): If True, includes a legend in the plot. Default is True.\nbar_width (np.timedelta64): The width of the bars representing each meal on the time axis. Default is 15 minutes.\npalette (str): The color palette to use for the stacked bars.\nalpha (float): The transparency of the stacked bars. Default is 0.7.\nax (Optional[plt.Axes]): The Matplotlib axis on which to plot the bar chart. If None, a new axis is created. Default is None.\nfigsize (Tuple[float, float]): The size of the figure to create. Default is (14, 3).\nReturns:\nNone: The function creates a stacked bar chart on the specified or newly created axis.*\n\nsource\n\n\nadd_size_legend\n\n add_size_legend (ax:matplotlib.axes._axes.Axes, sizes:List[int],\n                  size_scale:float, alpha:float, shift:int=0)\n\nAdd a size legend to a plot_meals_hbars plot using broken_barh.\n\nsource\n\n\nplot_meals_hbars\n\n plot_meals_hbars (diet_log:pandas.core.frame.DataFrame,\n                   x:str='collection_timestamp',\n                   y:str='short_food_category', size:str='weight_g',\n                   hue:str='short_food_category', participant_id:int=None,\n                   array_index:int=None, time_range:Tuple[str,str]=None,\n                   y_include:List[str]=None, y_exclude:List[str]=None,\n                   rename_categories:dict={'beef, veal, lamb, and other\n                   meat products': 'meat products', 'milk, cream cheese\n                   and yogurts': 'milk products', 'nuts, seeds, and\n                   products': 'nuts and seeds', 'eggs and their products':\n                   'eggs', 'pulses and products': 'pulses', 'fruit juices\n                   and soft drinks': 'juices and soft drinks', 'low\n                   calories and diet drinks': 'low cal. drinks', 'poultry\n                   and its products': 'poultry', 'pasta, grains and side\n                   dishes': 'grains', 'industrialized vegetarian food\n                   ready to eat': 'industrialized veg.'},\n                   legend:bool=True, size_legend:List[int]=[100, 200,\n                   500], size_scale:float=5, palette:str='muted',\n                   alpha:float=0.7, ax:matplotlib.axes._axes.Axes=None,\n                   figsize:Tuple[float,float]=(12, 6))\n\n*Plot a diet chart with bars representing meals and their size over time.\nArgs:\ndiet_log (pd.DataFrame): The dataframe containing the diet log data, with columns for timestamps, nutrients, and other measurements.\nx (str): The name of the column in `diet_log` representing the x-axis variable, such as timestamps. Default is 'collection_timestamp'.\ny (str): The name of the column in `diet_log` representing the y-axis variable, such as food categories. Default is 'short_food_category'.\nsize (str): The name of the column in `diet_log` representing the size of the bars. Default is 'weight_g'.\nhue (str): The name of the column in `diet_log` representing the color of the bars. Default is 'short_food_category'.\nparticipant_id (Optional[int]): The participant's ID to filter the diet log. If None, no filtering is done. Default is None.\ntime_range (Optional[Tuple[str, str]]): A tuple of strings representing the start and end dates for filtering the data. Format should be 'YYYY-MM-DD'. Default is None.\ny_include (List[str]): A list of strings representing the categories to include in the plot. Default is None.\ny_exclude (List[str]): A list of strings representing the categories to exclude from the plot. Default is None.\nrename_categories (dict): A dictionary mapping original food categories to shorter names. Default is SHORT_FOOD_CATEGORIES.\nlegend (bool): If True, includes a legend in the plot. Default is True.\nsize_legend (List[int]): A list of integers representing the sizes to include in the size legend. Default is [100, 200, 500].\nsize_scale (float): The scaling factor for the size of the bars. Default is 5.\npalette (str): The palette to use for the bars.\nalpha (float): The transparency of the bars. Default is 0.7.\nax (Optional[plt.Axes]): The Matplotlib axis on which to plot the lollipop chart. If None, a new axis is created. Default is None.\nfigsize (Tuple[float, float]): The size of the figure to create. Default is (12, 6).\nReturns:\nplt.Axes: The Matplotlib axis on which the chart was plotted.*\n\nsource\n\n\nplot_diet_cgm_sleep\n\n plot_diet_cgm_sleep (diet:pandas.core.frame.DataFrame=None,\n                      cgm:pandas.core.frame.DataFrame=None,\n                      sleep_events:pandas.core.frame.DataFrame=None,\n                      sleep_channels:pandas.core.frame.DataFrame=None,\n                      cgm_grid:List[int]=[0, 54, 70, 100, 140, 180],\n                      channel_filter:List[str]=['heart_rate', 'actigraph',\n                      'spo2'], participant_id=None, array_index=None,\n                      time_range:Tuple[str,str]=None, figsize=(14, 10),\n                      nutrient_kws:dict={}, meals_kws:dict={},\n                      cgm_kws:dict={}, events_kws:dict={},\n                      channels_kws:dict={})\n\n*Plot diet, CGM and sleep data together.\nArg:\ndiet (pd.DataFrame): Diet logging data. Set to None to remove from figure.\ncgm (pd.DataFrame): CGM data. Set to None to remove from figure.\nsleep_events (pd.DataFrame): Sleep events data. Set to None to remove from figure.\nsleep_channels (pd.DataFrame): Sleep channels data. Set to None to remove from figure.\ncgm_grid (List[int]): CGM grid lines. Default: [0, 54, 70, 100, 140, 180].\nchannel_filter (List[str]): Which sleep channels to include in the plot. Default: ['heart_rate', 'actigraph', 'spo2'].\nparticipant_id (int): Participant ID.\narray_index (int): Array index.\ntime_range (Tuple[str, str]): Time range to plot.\nfigsize (Tuple[int, int]): Figure size.\nnutrient_kws (dict): Keyword arguments for diet nutrients lollipop plot.\nmeals_kws (dict): Keyword arguments for diet meals plot.\ncgm_kws (dict): Keyword arguments for CGM plot.\nevents_kws (dict): Keyword arguments for sleep events plot.\nchannels_kws (dict): Keyword arguments for sleep channels plot.\nReturns:\nTimeSeriesFigure: The figure object containing the plots.*\n\n\nHow to plot diet logs\nThis module provides functions for plotting diet data, as well as a function for plotting diet, CGM and sleep data together.\nFirst, we will load the time series data for diet, CGM and sleep. (See also the dedicated modules for sleep and CGM.)\n\nfrom pheno_utils import PhenoLoader\n\npl = PhenoLoader('sleep')\nchannels_df = pl.load_bulk_data('channels_time_series')  # contains: heart_rate, spo2, respiratory_movement\nevents_df = pl.load_bulk_data('events_time_series')\n\ndiet_df = PhenoLoader('diet_logging').dfs['diet_logging']\ncgm_df = PhenoLoader('cgm').dfs['cgm']\n\nWarning: index is not unique for diet_logging\n\n\n/home/ec2-user/projects/pheno-utils/pheno_utils/pheno_loader.py:610: UserWarning: No date field found\n  warnings.warn(f'No date field found')\n/home/ec2-user/projects/pheno-utils/pheno_utils/pheno_loader.py:610: UserWarning: No date field found\n  warnings.warn(f'No date field found')\n/home/ec2-user/projects/pheno-utils/pheno_utils/pheno_loader.py:610: UserWarning: No date field found\n  warnings.warn(f'No date field found')\n\n\n\ndiet_df.head(5)\n\n\n\n\n\n\n\n\n\nshort_food_name\nfood_category\nweight_g\ncalories_kcal\ncarbohydrate_g\nlipid_g\nprotein_g\nsodium_mg\ndietary_fiber_g\nalcohol_g\n\n\nparticipant_id\ncollection_timestamp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n2020-06-21 16:06:00+03:00\nQuinoa\nPasta, Grains and Side dishes_wholewheat\n56.0\n78.3104\n12.1744\n1.2992\n2.8000\n37.1504\n1.4896\n0.0\n\n\n2020-06-21 16:06:00+03:00\nHummus Salad\nPulses and products\n80.0\n215.2000\n9.4400\n16.8000\n6.5600\n377.6000\n0.0000\nNaN\n\n\n2020-06-21 16:06:00+03:00\nMeatballs\nBeef, veal, lamb, and other meat products\n180.0\n311.0940\n16.1280\n15.4440\n24.7320\n1164.5460\n2.3904\n0.0\n\n\n2020-06-21 19:28:00+03:00\nBanana\nFruits\n128.0\n113.9200\n25.9072\n0.4224\n1.3952\n1.2800\n3.3280\n0.0\n\n\n2020-06-21 21:07:00+03:00\nBread\nBread\n60.0\n162.6000\n28.3800\n2.1000\n5.2800\n367.8000\n1.6200\n0.0\n\n\n\n\n\n\n\n\ncgm_df.head(5)\n\n\n\n\n\n\n\n\n\nglucose\n\n\nparticipant_id\ncollection_timestamp\n\n\n\n\n\n0\n2020-06-22 00:14:00+03:00\n106.2\n\n\n2020-06-22 00:29:00+03:00\n100.8\n\n\n2020-06-22 00:44:00+03:00\n97.2\n\n\n2020-06-22 00:59:00+03:00\n95.4\n\n\n2020-06-22 01:14:00+03:00\n93.6\n\n\n\n\n\n\n\nNext, we will use plot_diet_cgm_sleep to plot the data together.\n\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nplot_diet_cgm_sleep(diet_df, cgm_df, events_df, channels_df,\n                    channel_filter=['heart_rate', 'respiratory_movement', 'spo2'],\n                    time_range=('2020-06-22 08:00', '2020-06-23 10:00'))\n\n\n\n\n\n\n\n\nEach of the types of diet plots can be plotted independently as well. We will use TimeSeriesFigure, plot_nutrient_lollipop, plot_meals_hbars and plot_nutrient_bars to plot them together.\n\nfrom pheno_utils.timeseries_plots import TimeSeriesFigure\n\ng = TimeSeriesFigure(figsize=(14, 7))\n\ntime_range = ('2020-06-22 06:00', '2020-06-23 15:00')\n# Each call to the plot() methods adds a new time-synced subplot to the figure\ng.plot(plot_nutrient_lollipop, diet_df, size_scale=15,\n       time_range=time_range,\n       name='diet_pie')\ng.plot(plot_meals_hbars, diet_df,\n       time_range=time_range,\n       name='diet_meals', height=2)\ng.plot(plot_nutrient_bars, diet_df,\n       time_range=time_range,\n       label=None, n_axes=2, nut_exclude=['sodium'],\n       name='diet_bars')\ng.set_axis_padding(0.03)",
    "crumbs": [
      "Plots",
      "Diet logging plots"
    ]
  },
  {
    "objectID": "basic_plots.html",
    "href": "basic_plots.html",
    "title": "Basic plots",
    "section": "",
    "text": "source\n\nget_gender_indices\n\n get_gender_indices (df, gender='male', gender_col='sex')\n\n*Returns the indices of the requested gender from a specified column in a pandas DataFrame.\nParameters: - df: pandas DataFrame. - gender: str, ‘male’ or ‘female’, the gender to filter by. - gender_col: str, the name of the column containing gender information.\nReturns: - indices: Index object with the indices of the rows matching the requested gender.*\n\nsource\n\n\ndata_histplot\n\n data_histplot (data:pandas.core.frame.DataFrame, col:str,\n                feature_str:Optional[str]=None, gender_col:str='sex',\n                plot_both_genders:bool=True, ax=None)\n\n*Plots a histogram from a DataFrame for a specific column.\nArgs: data (pd.DataFrame): The DataFrame containing the data to plot. col (str): The name of the column to plot. feature_str (Optional[str], optional): The name of the feature to plot. Defaults to None. gender_col (str, optional): The name of the column containing gender information. Defaults to “sex”. plot_both_genders (bool, optional): Whether to plot both genders or just one. Defaults to True. ax ([type], optional): The axis to plot on. Defaults to None.*\n\n# Generate synthetic data\ndata = generate_synthetic_data(n=1000)\n\n\ndata_histplot(data=data, col=\"val1\", plot_both_genders=False)\n\n\n\n\n\n\n\n\n\ndata_histplot(data=data, col=\"val1\")\n\n\n\n\n\n\n\n\n\nsource\n\n\ndata_ecdfplot\n\n data_ecdfplot (data:pandas.core.frame.DataFrame, col:str,\n                feature_str:Optional[str]=None, gender_col:str='sex',\n                plot_both_genders:bool=True, ax=None)\n\n*Plots an empirical cumulative distribution function (ECDF) from a DataFrame for a specific column.\nArgs: data (pd.DataFrame): The DataFrame containing the data to plot. col (str): The name of the column to plot. feature_str (Optional[str], optional): The name of the feature to plot. Defaults to None. gender_col (str, optional): The name of the column containing gender information. Defaults to “sex”. plot_both_genders (bool, optional): Whether to plot both genders or just one. Defaults to True. ax ([type], optional): The axis to plot on. Defaults to None.*\n\ndata_ecdfplot(data=data, col=\"val1\", plot_both_genders=False)\n\n\n\n\n\n\n\n\n\ndata_ecdfplot(data=data, col=\"val1\")\n\n\n\n\n\n\n\n\n\nsource\n\n\nhist_ecdf_plots\n\n hist_ecdf_plots (data:pandas.core.frame.DataFrame, col:str,\n                  feature_str:Optional[str]=None, gender_col:str='sex',\n                  plot_both_genders:bool=True)\n\n*Plots histograms and empirical cumulative distribution functions (ECDFs) from a DataFrame for a specific column.\nArgs: data: The input DataFrame containing the data to plot. col: The column name to plot. feature_str: The title of the plot. If not provided, the column name will be used. gender_col: The column name indicating sex (default is ‘sex’ - female:0; male:1). plot_both_genders (bool, optional): Whether to plot both genders or just one. Defaults to True.\nReturns: None*\n\nhist_ecdf_plots(data=data, col=\"val1\")\n\n\n\n\n\n\n\n\n\nsource\n\n\nplot_stats\n\n plot_stats (data:pandas.core.frame.DataFrame, col:str,\n             ax:matplotlib.axes._axes.Axes, color:str,\n             x_position:float=0.3, label:Optional[str]='All')\n\n*Adds a text box to an axis object with summary statistics for a given column in a pandas DataFrame.\nArgs: data (pd.DataFrame): The pandas DataFrame containing the data to calculate statistics for. col (str): The name of the column to calculate statistics for. ax (plt.Axes): The axis object to add the text box to. color (str): The color of the text box. x_position (float, optional): The x position of the text box. Defaults to 0.3. label (Optional[str], optional): The label to display in the text box. Defaults to “All”.*\n\nsource\n\n\nplot_hist_stats\n\n plot_hist_stats (data:pandas.core.frame.DataFrame, col:str,\n                  feature_str:Optional[str]=None, gender_col:str='sex',\n                  plot_both_genders:bool=True)\n\n*Plots a histogram of a given column in a pandas DataFrame and adds summary statistics to the plot.\nArgs: data (pd.DataFrame): The pandas DataFrame containing the data to plot. col (str): The name of the column to plot. feature_str (Optional[str], optional): A string describing the feature being plotted. Defaults to None. gender_col (str, optional): The name of the column containing gender information. Defaults to “sex”. plot_both_genders (bool, optional): Whether to plot statistics separately for males and females. Defaults to True.*\n\n# Generate synthetic data\ndata = generate_synthetic_data(n=1000)\n\n\nplot_hist_stats(data, \"val1\", plot_both_genders=False)\n\n\n\n\n\n\n\n\n\nplot_hist_stats(data, \"val1\")\n\n\n\n\n\n\n\n\n\nsource\n\n\nplot_data_collection\n\n plot_data_collection (data:pandas.core.frame.DataFrame,\n                       date_col:str='collection_date',\n                       feature_str:Optional[str]=None,\n                       ax:Optional[matplotlib.axes._axes.Axes]=None)\n\n*Plots a histogram of the specified column in a pandas DataFrame and excludes the last point from the plot.\nArgs: data (pd.DataFrame): The pandas DataFrame containing the data to plot. date_col (str, optional): The name of the column containing the dates. Defaults to “collection_date”. feature_str (Optional[str], optional): The name of the feature to plot. If None, the name of the date column will be used. Defaults to None. ax (Optional[plt.Axes], optional): The axis object to plot on. If None, a new figure and axis will be created. Defaults to None.*\n\nplot_data_collection(data, date_col=\"date_of_research_stage\", feature_str=\"val1\")\n\n\n\n\n\n\n\n\n\nsource\n\n\nshow_fundus\n\n show_fundus (fname:str)\n\n\nsource\n\n\nplot_horizontal_count_bars\n\n plot_horizontal_count_bars (data, column_name, hue=None, n=20)\n\n*Function to plot horizontal bar charts with counts.\nParameters: - data (pd.DataFrame): DataFrame containing the data - y (str): Column name for the y-axis - hue (str, optional): Column name for the hue (default is None) - n (int, optional): Number of top categories to display (default is None, showing all)\nReturns: - ax (Axes object): The plot*\n\n# Generate categorical synthetic data\ncategorical_data = generate_categorical_synthetic_data(n=1000)\n\n\nplot_horizontal_count_bars(categorical_data, 'val1', hue='val2', n=3)\n\n\n\n\n\n\n\n\n\nplot_horizontal_count_bars(categorical_data, 'val1', hue=None)",
    "crumbs": [
      "Plots",
      "Basic plots"
    ]
  },
  {
    "objectID": "cgm_plots.html",
    "href": "cgm_plots.html",
    "title": "CGM plots",
    "section": "",
    "text": "source\n\nCGMPlot\n\n CGMPlot (cgm_df:pandas.core.frame.DataFrame,\n          diet_df:Optional[pandas.core.frame.DataFrame]=None,\n          cgm_date_col:str='collection_timestamp', gluc_col:str='glucose',\n          diet_date_col:str='collection_timestamp',\n          diet_text_col:str='short_food_name',\n          ax:Optional[matplotlib.axes._axes.Axes]=None, smooth:bool=False,\n          sleep_tuples:Optional[List[Tuple[pandas._libs.tslibs.timestamps.\n          Timestamp,pandas._libs.tslibs.timestamps.Timestamp]]]=None)\n\n*Initialize a CGMPlot object.\nArgs: cgm_df (pd.DataFrame): DataFrame containing the glucose measurements. diet_df (Optional[pd.DataFrame], optional): DataFrame containing the diet data. Defaults to None. cgm_date_col (str, optional): Name of the date column in cgm_df. Defaults to “collection_timestamp”. gluc_col (str, optional): Name of the glucose column in cgm_df. Defaults to “glucose”. diet_date_col (str, optional): Name of the date column in diet_df. Defaults to “collection_timestamp”. diet_text_col (str, optional): Name of the text column in diet_df. Defaults to “short_food_name”. ax (Optional[plt.Axes], optional): Matplotlib Axes object to plot on. Defaults to None. smooth (bool, optional): Apply smoothing to the glucose curve. Defaults to False. sleep_tuples (Optional[List[Tuple[pd.Timestamp, pd.Timestamp]]], optional): List of sleep start and end times. Defaults to None.*\n\ncgm_df= pd.read_parquet(\"./examples/cgm/cgm.parquet\")\ncgm_df.head()\n\n\n\n\n\n\n\n\n\nglucose\n\n\nparticipant_id\ncollection_timestamp\n\n\n\n\n\n0\n2020-06-22 00:14:00+03:00\n106.2\n\n\n2020-06-22 00:29:00+03:00\n100.8\n\n\n2020-06-22 00:44:00+03:00\n97.2\n\n\n2020-06-22 00:59:00+03:00\n95.4\n\n\n2020-06-22 01:14:00+03:00\n93.6\n\n\n\n\n\n\n\n\ndiet_df = pd.read_parquet(\"./examples/diet_logging/diet_logging.parquet\")\ndiet_df.head()\n\n\n\n\n\n\n\n\n\nshort_food_name\nfood_category\nweight_g\ncalories_kcal\ncarbohydrate_g\nlipid_g\nprotein_g\nsodium_mg\nalcohol_g\ndietary_fiber_g\n\n\nparticipant_id\ncollection_timestamp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n2020-06-21 16:06:00+03:00\nQuinoa\nPasta, Grains and Side dishes_wholewheat\n56.0\n78.3104\n12.1744\n1.2992\n2.8000\n37.1504\n0.0\n1.4896\n\n\n2020-06-21 16:06:00+03:00\nHummus Salad\nPulses and products\n80.0\n215.2000\n9.4400\n16.8000\n6.5600\n377.6000\nNaN\n0.0000\n\n\n2020-06-21 16:06:00+03:00\nMeatballs\nBeef, veal, lamb, and other meat products\n180.0\n311.0940\n16.1280\n15.4440\n24.7320\n1164.5460\n0.0\n2.3904\n\n\n2020-06-21 19:28:00+03:00\nBanana\nFruits\n128.0\n113.9200\n25.9072\n0.4224\n1.3952\n1.2800\n0.0\n3.3280\n\n\n2020-06-21 21:07:00+03:00\nBread\nBread\n60.0\n162.6000\n28.3800\n2.1000\n5.2800\n367.8000\n0.0\n1.6200\n\n\n\n\n\n\n\n\nstart_date = pd.to_datetime('2020-06-22', utc=True).tz_convert('Asia/Jerusalem')\nend_date = pd.to_datetime('2020-06-24',utc=True).tz_convert('Asia/Jerusalem')\n\n\nsample_cgm = cgm_df[(cgm_df.index.get_level_values('collection_timestamp') &gt;= start_date) \\\n                     & (cgm_df.index.get_level_values('collection_timestamp') &lt;= end_date)]\nsample_diet = diet_df[(diet_df.index.get_level_values('collection_timestamp') &gt;= start_date) \\\n                     & (diet_df.index.get_level_values('collection_timestamp') &lt;= end_date)]\n\n\ncgmplt = CGMPlot(cgm_df=sample_cgm,\n                 gluc_col=\"glucose\",\n                 diet_df=sample_diet,\n                 smooth=True)\ncgmplt.plot()\n\n\n\n\n\n\n\n\n\n\nAGP\n\nsource\n\nAGP\n\n AGP (cgm_df:pandas.core.frame.DataFrame,\n      cgm_date_col:str='collection_timestamp', gluc_col:str='glucose',\n      ax:Optional[matplotlib.axes._axes.Axes]=None)\n\n*Initialize an AGP object.\nArgs: cgm_df (pd.DataFrame): DataFrame containing the glucose measurements. cgm_date_col (str, optional): Name of the date column in cgm_df. Defaults to “collection_timestamp”. gluc_col (str, optional): Name of the glucose column in cgm_df. Defaults to “glucose”. ax (Optional[plt.Axes], optional): Matplotlib Axes object to plot on. Defaults to None.*\n\nagp = AGP(cgm_df=cgm_df.reset_index(), cgm_date_col=\"collection_timestamp\", gluc_col=\"glucose\")\nagp.plot()",
    "crumbs": [
      "Plots",
      "CGM plots"
    ]
  },
  {
    "objectID": "timeseries_plots.html",
    "href": "timeseries_plots.html",
    "title": "Time series plots",
    "section": "",
    "text": "source\n\nformat_timeseries\n\n format_timeseries (df:pandas.core.frame.DataFrame,\n                    participant_id:int=None, array_index:int=None,\n                    time_range:Tuple[str,str]=None,\n                    x_start:str='collection_timestamp',\n                    x_end:str='collection_timestamp', unique:bool=False)\n\n*Reformat and filter a time series DataFrame based on participant ID, array index, and date range.\nArgs:\ndf (pd.DataFrame): The DataFrame to filter.\nparticipant_id (int): The participant ID to filter by.\narray_index (int): The array index to filter by.\ntime_range: The date range to filter by. Can be a tuple of two dates / times or two strings.\nx_start (str): The name of the column containing the start time.\nx_end (str): The name of the column containing the end time.\nunique (bool): Whether to remove duplicate rows.\nReturns:\npd.DataFrame: The filtered DataFrame*\n\nsource\n\n\nformat_xticks\n\n format_xticks (ax:matplotlib.axes._axes.Axes, xticks:Iterable=None,\n                format:str='%d/%m\\n%H:%M', **kwargs)\n\nFormat datestrings on x axis\n\nsource\n\n\nTimeSeriesFigure\n\n TimeSeriesFigure (figsize:tuple=(10, 6), padding:float=0.05)\n\n*Initialize a TimeSeriesFigure instance. This class is used to create and manage a figure with multiple axes for time series data.\nArgs:\nfigsize (tuple): Size of the figure (width, height) in inches.\npadding (float): The amount of padding to add between axes as a fraction of the figure height.*\n\nsource\n\n\nget_color_map\n\n get_color_map (data:pandas.core.frame.DataFrame, hue:str, palette:str)\n\n*Get a color map for a specific column in the data.\nArgs:\ndata (pd.DataFrame): The data to get the color map from.\nhue (str): The column name to use for the color map.\npalette (str): The name of the colormap to use.\nReturns:\npd.DataFrame: A DataFrame with the color map.*\n\nsource\n\n\nget_events_period\n\n get_events_period (events_filtered:pandas.core.frame.DataFrame,\n                    period_start:str, period_end:str, period_name:str,\n                    col:str='event', first_start:bool=True,\n                    first_end:bool=True, include_start:bool=True,\n                    include_end:bool=True,\n                    x_start:str='collection_timestamp',\n                    x_end:str='event_end')\n\n*Get the period of time between the start and end events.\nArgs:\nevents_filtered (pd.DataFrame): The events DataFrame.\nperiod_start (str): The label of the start event.\nperiod_end (str): The label of the end event.\nperiod_name (str): The label to assign to the period.\ncol (str): The column name for the event labels. Default is 'event'.\nfirst_start (bool): If True, get the first start event. Default is True.\nfirst_end (bool): If True, get the first end event. Default is True.\ninclude_start (bool): If True, include the start event in the period. Default is True.\ninclude_end (bool): If True, include the end event in the period. Default is True.\nx_start (str): The column name for the start time of the event. Default is 'collection_timestamp'.\nx_end (str): The column name for the end time of the event. Default is 'event_end'.\nReturns:\npd.DataFrame: The period of events in the same format as the input DataFrame.*\n\nsource\n\n\nprep_to_plot_timeseries\n\n prep_to_plot_timeseries (data:pandas.core.frame.DataFrame, x_start:str,\n                          x_end:str, hue:str, label:str,\n                          participant_id:int, array_index:int,\n                          time_range:Tuple[str,str],\n                          y_include:Iterable[str],\n                          y_exclude:Iterable[str],\n                          add_columns:Iterable[str]=None, palette='muted')\n\n*Prepare timeseries / events data for plotting.\nArgs:\nevents (pd.DataFrame): The timeseries / events dataframe.\nx_start (str): The column name for the start time of the event.\nx_end (str): The column name for the end time of the event.\nhue (str): The column name for the color of the event.\nlabel (str): The column name for the label of the event.\nparticipant_id (int): The participant ID to filter events by.\narray_index (int): The array index to filter events by.\ntime_range (Iterable[str]): The time range to filter events by.\ny_include (Iterable[str]): The list of values to include in the plot.\ny_exclude (Iterable[str]): The list of values to exclude from the plot.\nadd_columns (Iterable[str]): Additional columns to include in the plot.\npalette (str): The name of the colormap to use for coloring events.\nReturns:\nTuple[pd.DataFrame, pd.DataFrame]: The filtered events dataframe and the color map.*\n\nsource\n\n\nplot_events_fill\n\n plot_events_fill (events:pandas.core.frame.DataFrame,\n                   x_start:str='collection_timestamp',\n                   x_end:str='event_end', hue:str='channel',\n                   label:str=None, participant_id:Optional[int]=None,\n                   array_index:Optional[int]=None,\n                   time_range:Optional[Tuple[str,str]]=None,\n                   y_include:Optional[Iterable[str]]=None,\n                   y_exclude:Optional[Iterable[str]]=None,\n                   legend:bool=True, palette:str='muted',\n                   alpha:Optional[float]=0.5,\n                   ax:Optional[matplotlib.axes._axes.Axes]=None,\n                   figsize:Iterable[float]=[12, 6])\n\n*Plot events as filled regions on a time series plot.\nArgs:\nevents (pd.DataFrame): The events dataframe.\nx_start (str): The column name for the start time of the event.\nx_end (str): The column name for the end time of the event.\nhue (str): The column name for the color of the event.\nlabel (str): The column name for the label of the event.\nparticipant_id (int): The participant ID to filter events by.\narray_index (int): The array index to filter events by.\ntime_range (Iterable[str]): The time range to filter events by.\ny_include (Iterable[str]): The list of values to include in the plot.\ny_exclude (Iterable[str]): The list of values to exclude from the plot.\nlegend (bool): Whether to show the legend.\npalette (str): The name of the palette to use for coloring events.\nalpha (float): The transparency of the filled regions.\nax (plt.Axes): The axis to plot on. If None, a new figure is created.\nfigsize (Tuple[float, float]): The size of the figure (width, height) in inches.*\n\nsource\n\n\nplot_events_bars\n\n plot_events_bars (events:pandas.core.frame.DataFrame,\n                   x_start:str='collection_timestamp',\n                   x_end:str='event_end', y:str='event',\n                   hue:str='channel', participant_id:Optional[int]=None,\n                   array_index:Optional[int]=None,\n                   time_range:Optional[Tuple[str,str]]=None,\n                   y_include:Optional[Iterable[str]]=None,\n                   y_exclude:Optional[Iterable[str]]=None,\n                   legend:bool=True, palette:str='muted',\n                   alpha:Optional[float]=0.7,\n                   ax:Optional[matplotlib.axes._axes.Axes]=None,\n                   figsize:Tuple[float,float]=(12, 6))\n\n*Plot events as bars on a time series plot.\nArgs:\nevents (pd.DataFrame): The events dataframe.\nx_start (str): The column name for the start time of the event.\nx_end (str): The column name for the end time of the event.\ny (str): The column name for the y-axis values.\nhue (str): The column name for the color of the event.\nparticipant_id (int): The participant ID to filter events by.\narray_index (int): The array index to filter events by.\ntime_range (Tuple[str, str]): The time range to filter events by.\ny_include (Iterable[str]): The list of values to include in the plot.\ny_exclude (Iterable[str]): The list of values to exclude from the plot.\nlegend (bool): Whether to show the legend.\npalette (str): The name of the colormap to use for coloring events.\nalpha (float): The transparency of the bars. Default is 0.7.\nax (plt.Axes): The axis to plot on. If None, a new figure is created.\nfigsize (Tuple[float, float]): The size of the figure (width, height) in inches.*\n\n\nHow to plot time series\nThe class TimeSeriesFigure provides a user-friendly interface for plotting multiple channels of time series data.\nFirst, we will load time series DFs from the sleep monitoring dataset. The data includes sleep events, and sensor channels for heart rate, respiratory movement, and oxygen saturation.\n\nfrom pheno_utils import PhenoLoader\n\npl = PhenoLoader('sleep')\nchannels_df = pl.load_bulk_data('channels_time_series', pivot='source')\nevents_df = pl.load_bulk_data('events_time_series')\n\n/home/ec2-user/projects/pheno-utils/pheno_utils/pheno_loader.py:610: UserWarning: No date field found\n  warnings.warn(f'No date field found')\n\n\nAny plotting function that accepts an ax argument can be used with TimeSeriesFigure. The pheno-utils package includes a number of functions that are useful for plotting time series data, such as plot_events_bars and plot_events_fill, however standard seaborn plotting functions (and others) can also be used.\n\nsns.set_style('whitegrid')\n\ng = TimeSeriesFigure()\n\nchannels_df = format_timeseries(channels_df).set_index('collection_timestamp')\ng.plot(sns.lineplot, channels_df, x='collection_timestamp', y='heart_rate',\n       name='heart_rate')  # Named axis 'heart_rate'\n\n# You can also use the `sharex` argument to share the x-axis between plots\n# Named axes, such as 'heart_rate', can be referred to by name\ng.plot(sns.lineplot, channels_df, x='collection_timestamp', y='spo2',\n       sharex='heart_rate')\n\n# You can increase the relative height of the plot by passing a `height` argument\ng.plot(sns.lineplot, channels_df, x='collection_timestamp', y='respiratory_movement',\n       sharex='heart_rate', height=1.5)\n\n# You may add a plot to an existing axes by passing an `ax` argument to the plotting function\n# Named axes, such as 'heart_rate', can be referred to by name\nstage_events = ['Wake', 'Light Sleep', 'Deep Sleep', 'REM']  # Include only sleep stage events\ng.plot(plot_events_fill, events_df, hue='event', y_include=stage_events,\n       ax='heart_rate')\n\napnea_events = ['Resp. Event', 'Desaturation', 'A/H obstructive', 'A/H central', 'A/H unclassified']\ng.plot(plot_events_bars, events_df, hue='event', y_include=apnea_events, height=1.5)\n\n# Control functions to conveniently modify all axes\ng.set_periodic_ticks('1h')\ng.set_axis_padding(0.05)\ng.set_axis_properties(xlabel='')",
    "crumbs": [
      "Plots",
      "Time series plots"
    ]
  },
  {
    "objectID": "age_reference_plots.html",
    "href": "age_reference_plots.html",
    "title": "Age reference plots",
    "section": "",
    "text": "source\n\nget_gam_expectiles\n\n get_gam_expectiles (X:numpy.ndarray, y:numpy.ndarray,\n                     expectiles:List[float]=[0.03, 0.1, 0.5, 0.9, 0.97])\n\n*Fit Expectile Generalized Additive Models (GAMs) for given expectiles.\nArgs: X (ndarray): Feature data for the model. y (ndarray): Target variable for the model. expectiles (List[float]): List of expectiles to fit. Default is [0.03, 0.1, 0.5, 0.9, 0.97].\nReturns: Tuple[ndarray, Dict[str, ndarray]]: A tuple containing a grid of X values for prediction and a dictionary with expectiles as keys and their corresponding model predictions as values.*\n\nsource\n\n\nAgeRefPlot\n\n AgeRefPlot (data:pandas.core.frame.DataFrame, val_col:str,\n             age_col:str='age_at_research_stage', sex_col:str='sex',\n             sex:Optional[int]=None, val_color:Optional[str]=None,\n             ax_main:Optional[matplotlib.axes._axes.Axes]=None,\n             ax_agehist:Optional[matplotlib.axes._axes.Axes]=None,\n             ax_valhist:Optional[matplotlib.axes._axes.Axes]=None,\n             age_bins:Optional[numpy.ndarray]=None,\n             val_bins:Optional[numpy.ndarray]=None, linear_fit:bool=True,\n             expectiles:Optional[List]=[0.03, 0.1, 0.5, 0.9, 0.97],\n             thresholds:Optional[List]=None, top_disp_perc:float=99,\n             bottom_disp_perc:float=1, robust:bool=True, scale:float=1.0,\n             transform:Optional[Callable]=None, make_fig:bool=True)\n\n*Initializes the AgeRefPlot class.\nArgs: data (pd.DataFrame): A pandas DataFrame containing the data. val_col (str): The name of the value column in the DataFrame. age_col (str): The name of the age column in the DataFrame. sex_col (str): The name of the sex column in the DataFrame. sex (Optional[int], optional): The sex to filter the data by. 0 for females and 1 for males. Defaults to None. val_color (Optional[str], optional): The color to use for the value plot. Defaults to None. ax_main (Optional[plt.Axes], optional): The main axis for the plot. Defaults to None. ax_agehist (Optional[plt.Axes], optional): The axis for the age histogram. Defaults to None. ax_valhist (Optional[plt.Axes], optional): The axis for the value histogram. Defaults to None. age_bins (Optional[np.ndarray], optional): The age bins for the histograms. Defaults to None. val_bins (Optional[np.ndarray], optional): The value bins for the histograms. Defaults to None. linear_fit (bool, optional): Whether to perform a linear fit on the data. Defaults to True. expectiles (Optional[List], optional): Whether to calculate and shpe gam expectiles or not. Defaults to [0.03, 0.1, 0.5, 0.9, 0.97]. top_disp_perc (float, optional): The top percentile to use for display. Defaults to 99. bottom_disp_perc (float, optional): The bottom percentile to use for display. Defaults to 1. robust (bool, optional): Whether to use a robust regression method (HuberRegressor) instead of ordinary least squares for linear_fit. Defaults to True. scale (float, optional): The scaling factor for the value column. Defaults to 1. transform (Optional[Callable], optional): The transformation function to apply to the value column. Defaults make_fig (bool, optional): Whether to create a new figure if axes are not provided. Defaults to True.*\n\ndata = generate_synthetic_data(n=1000)\n\n\nrefplot = AgeRefPlot(data, \"val1\")\nrefplot.plot()\nrefplot.plot_thresholds([-np.inf, 50, 120, np.inf], cmap='RdYlGn_r')\n\n\n\n\n\n\n\n\n\nsource\n\n\nGenderAgeRefPlot\n\n GenderAgeRefPlot (data:pandas.core.frame.DataFrame, val_col:str,\n                   age_col:str='age_at_research_stage', sex_col:str='sex',\n                   age_bins:Optional[numpy.ndarray]=None,\n                   val_bins:Optional[numpy.ndarray]=None,\n                   linear_fit:bool=True, expectiles:Optional[List]=[0.03,\n                   0.1, 0.5, 0.9, 0.97], top_disp_perc:float=99,\n                   bottom_disp_perc:float=1, robust:bool=True,\n                   scale:float=1.0, transform:Optional[Callable]=None)\n\n*Initializes the GenderAgeRefPlot class.\nArgs: data (pd.DataFrame): The input data containing age, value, and gender columns. val_col (str): The name of the value column in the data. age_col (str): The name of the age column in the DataFrame. sex_col (str): The name of the sex column in the DataFrame. age_bins (np.ndarray, optional): An array of age bin edges. val_bins (np.ndarray, optional): An array of value bin edges. linear_fit (bool, optional): Whether to fit a linear regression line. Defaults to True. expectiles (Optional[List], optional): Whether to calculate and shpe gam expectiles or not. Defaults to [0.03, 0.1, 0.5, 0.9, 0.97]. top_disp_perc (float, optional): The top percentile for data display. Defaults to 99. bottom_disp_perc (float, optional): The bottom percentile for data display. Defaults to 1. robust (bool, optional): Whether to use a robust linear regression. Defaults to True. scale (float, optional): The scaling factor for the data. Defaults to 1. transform (Callable, optional): An optional function to apply to the data. Defaults to None.*\n\ngender_refplots = GenderAgeRefPlot(data, \"val1\")\ngender_refplots.plot()\ngender_refplots.plot_thresholds([-np.inf, 50, 120, np.inf], cmap='RdYlGn')",
    "crumbs": [
      "Plots",
      "Age reference plots"
    ]
  },
  {
    "objectID": "ecg_analysis.html",
    "href": "ecg_analysis.html",
    "title": "ECG analysis",
    "section": "",
    "text": "source\n\nvis_ecg\n\n vis_ecg (values_df:pandas.core.frame.DataFrame)\n\n*Visualize ECG data for 12 leads.\nArgs: values_df (pd.DataFrame): A DataFrame containing ECG data with 12 columns, one for each lead.\nReturns: None: Displays a 3x4 grid of ECG plots for the 12 leads.*",
    "crumbs": [
      "Analysis",
      "ECG analysis"
    ]
  },
  {
    "objectID": "meta_loader.html",
    "href": "meta_loader.html",
    "title": "Metadata loader",
    "section": "",
    "text": "source\n\nMetaLoader\n\n MetaLoader (base_path:str='nbs/examples/', cohort:str=None,\n             flexible_field_search:bool=False, errors:str='warn',\n             **kwargs)\n\n*Class to load multiple dictionaries and allows to easily access the relevant fields.\nArgs:\nbase_path (str, optional): The base path where the data is stored. Defaults to DATASETS_PATH.\ncohort (str, optional): The name of the cohort within the dataset. Defaults to COHORT.\nflexible_field_search (bool, optional): Whether to allow regex field search. Defaults to False.\nerrors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n    Possible values are 'raise', 'warn' and 'ignore'. Defaults to 'raise'.\n**kwargs: Additional keyword arguments to pass to a DataLoader class.\nAttributes:\ndicts (pd.DataFrame): A dictionary of data dictionaries (dataframes) of all availbale datasets in the base_path.\nfields (list): A list of all fields.\ncohort (str): The name of the cohort being used.\nbase_path (str): The base path where the data is stored.\nflexible_field_search (bool): Whether to allow regex field search.\nerrors (str): Whether to raise an error or issue a warning if missing data is encountered.\nkwargs (dict): Additional keyword arguments to pass to a DataLoader class.*\n\n# os.path.join(DATASETS_PATH, '*')\nos.listdir(DATASETS_PATH)\n\n['cgm', 'diet_logging', 'events', 'fundus', 'sleep', 'metadata']\n\n\nThe MetaLoader can be used to query all availbale fields throughout all datasets. In the following example, 3 datasets are available.\n\nml = MetaLoader()\nml\n\nMetaLoader for: examples/*\nwith 83 fields\n4 datasets:\n['cgm'\n 'diet_logging'\n 'fundus'\n 'sleep']\n\n\nThe object contains only the data dictionaries (metadata) of these datasets, where the columns correspond to columns in the data tables of the dataset (e.g., fundus).\n\nml.dicts['fundus']\n\n\n\n\n\n\n\ntabular_field_name\nfundus_image_left\nfundus_image_right\ncollection_date\nfractal_dimension_left\nfractal_dimension_right\n\n\n\n\ndataset\nfundus\nfundus\nfundus\nfundus\nfundus\n\n\nfield_string\nFundus image (left)\nFundus image (right)\nCollection date (YYYY-MM-DD)\nFractal dimension (left)\nFractal dimension (right)\n\n\ndescription_string\nFundus image (left)\nFundus image (right)\nCollection date (YYYY-MM-DD)\nFractal dimension (left)\nFractal dimension (right)\n\n\nparent_dataframe\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nrelative_location\nfundus/fundus.parquet\nfundus/fundus.parquet\nfundus/fundus.parquet\nfundus/fundus.parquet\nfundus/fundus.parquet\n\n\nvalue_type\nText\nText\nDate\nContinuous\nContinuous\n\n\nunits\n&lt;NA&gt;\n&lt;NA&gt;\nTime\nTime\nTime\n\n\nsampling_rate\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nfield_type\nImage file (individual)\nImage file (individual)\nData\nData\nData\n\n\narray\nSingle\nSingle\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n10K\n10K\n\n\ndata_type\nimage\nimage\ntabular\ntabular\ntabular\n\n\ndebut\n2021-02-17\n2021-02-17\n2021-02-17\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nstring\nstring\ndatetime64[ns]\nfloat\nfloat\n\n\n\n\n\n\n\nYou can query fields from multiple datasets directly.\n\nml[['glucose', 'fundus_image_left', 'fundus/collection_date']]\n\n\n\n\n\n\n\ntabular_field_name\ncgm/glucose\nfundus/fundus_image_left\nfundus/collection_date\n\n\n\n\ndataset\ncgm\nfundus\nfundus\n\n\nfield_string\nGlucose\nFundus image (left)\nCollection date (YYYY-MM-DD)\n\n\ndescription_string\ncgm temporal glucose values\nFundus image (left)\nCollection date (YYYY-MM-DD)\n\n\nparent_dataframe\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nrelative_location\ncgm/cgm.parquet\nfundus/fundus.parquet\nfundus/fundus.parquet\n\n\nvalue_type\nSeries data, continous\nText\nDate\n\n\nunits\nmg/dl\n&lt;NA&gt;\nTime\n\n\nsampling_rate\n15min\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nfield_type\nContinuous\nImage file (individual)\nData\n\n\narray\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n\n\ndata_type\ntime series\nimage\ntabular\n\n\ndebut\n2018-12-27\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nfloat\nstring\ndatetime64[ns]\n\n\n\n\n\n\n\nNote that in the example above, for collection_date (that is common to all datasets) the dataset is specified in the prefix fundus/. Therefore, the loader returns the field from the fundus imaging dataset. Omitting this prefix will return all collection_date fields in the Human Phenotype Project.\nYou can then use the MetaLoader to load the actual data of fields from multiple datasets. Here we load glucose from the CGM dataset, and fundus_image_left from the fundus dataset.\n\ndf1 = ml.load(['glucose'])\ndf1\n\n\n\n\n\n\n\n\n\n\nglucose\n\n\nparticipant_id\ncollection_timestamp\nconnection_id\n\n\n\n\n\n0\n2020-05-25 10:48:00+03:00\n1000001\n111.6\n\n\n2020-05-25 11:03:00+03:00\n1000001\n79.2\n\n\n2020-05-25 11:18:00+03:00\n1000001\n84.6\n\n\n2020-05-25 11:33:00+03:00\n1000001\n106.2\n\n\n2020-05-25 11:48:00+03:00\n1000001\n102.6\n\n\n...\n...\n...\n\n\n2020-05-30 15:03:00+03:00\n1000001\n90.0\n\n\n2020-05-30 15:18:00+03:00\n1000001\n99.0\n\n\n2020-05-30 15:33:00+03:00\n1000001\n106.2\n\n\n2020-05-30 15:48:00+03:00\n1000001\n99.0\n\n\n2020-05-30 16:03:00+03:00\n1000001\n84.6\n\n\n\n\n502 rows × 1 columns\n\n\n\n\ndf2 = ml.load(['fundus_image_left'])\ndf2\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n/path/to/file\n\n\n1\n10k\n00_00_visit\n0\n/path/to/file\n\n\n2\n10k\n00_00_visit\n0\n/path/to/file\n\n\n3\n10k\n00_00_visit\n0\n/path/to/file\n\n\n4\n10k\n00_00_visit\n0\n/path/to/file\n\n\n\n\n\n\n\n\ndf3 = ml.load(['glucose' ,'fundus_image_left'])\ndf3\n\n\n\n\n\n\n\n\n\n\n\n\nglucose\nfundus_image_left\n\n\nparticipant_id\ncollection_timestamp\nconnection_id\ncohort\nresearch_stage\n\n\n\n\n\n\n0\n2020-05-25 10:48:00+03:00\n1000001\n10k\n00_00_visit\n111.6\n/path/to/file\n\n\n2020-05-25 11:03:00+03:00\n1000001\n10k\n00_00_visit\n79.2\n/path/to/file\n\n\n2020-05-25 11:18:00+03:00\n1000001\n10k\n00_00_visit\n84.6\n/path/to/file\n\n\n2020-05-25 11:33:00+03:00\n1000001\n10k\n00_00_visit\n106.2\n/path/to/file\n\n\n2020-05-25 11:48:00+03:00\n1000001\n10k\n00_00_visit\n102.6\n/path/to/file\n\n\n...\n...\n...\n...\n...\n...\n\n\n2020-05-30 16:03:00+03:00\n1000001\n10k\n00_00_visit\n84.6\n/path/to/file\n\n\n1\nNaT\nNaN\n10k\n00_00_visit\nNaN\n/path/to/file\n\n\n2\nNaT\nNaN\n10k\n00_00_visit\nNaN\n/path/to/file\n\n\n3\nNaT\nNaN\n10k\n00_00_visit\nNaN\n/path/to/file\n\n\n4\nNaT\nNaN\n10k\n00_00_visit\nNaN\n/path/to/file\n\n\n\n\n506 rows × 2 columns\n\n\n\n\nml.load(['glucose' ,'fundus_image_left', 'fundus/collection_date']).head()\n\n\n\n\n\n\n\n\n\n\n\n\nglucose\nfundus_image_left\ncollection_date\n\n\nparticipant_id\ncollection_timestamp\nconnection_id\ncohort\nresearch_stage\n\n\n\n\n\n\n\n0\n2020-05-25 10:48:00+03:00\n1000001\n10k\n00_00_visit\n111.6\n/path/to/file\n2022-11-16\n\n\n2020-05-25 11:03:00+03:00\n1000001\n10k\n00_00_visit\n79.2\n/path/to/file\n2022-11-16\n\n\n2020-05-25 11:18:00+03:00\n1000001\n10k\n00_00_visit\n84.6\n/path/to/file\n2022-11-16\n\n\n2020-05-25 11:33:00+03:00\n1000001\n10k\n00_00_visit\n106.2\n/path/to/file\n2022-11-16\n\n\n2020-05-25 11:48:00+03:00\n1000001\n10k\n00_00_visit\n102.6\n/path/to/file\n2022-11-16\n\n\n\n\n\n\n\nYou may use more flexible search queries using regex and various properties of the fields. Both the get() method and load() method support the same syntax.\n\nExample: get all bulk data fields.\n\n\nml.get('Time series', flexible=True, prop='field_type')\n\n\n\n\n\n\n\ntabular_field_name\ncgm/cgm_filename\n\n\n\n\ndataset\ncgm\n\n\nfield_string\nCGM timeseries\n\n\ndescription_string\nName of the file containing the participants' ...\n\n\nparent_dataframe\n&lt;NA&gt;\n\n\nrelative_location\ncgm/cgm.parquet\n\n\nvalue_type\nText\n\n\nunits\n&lt;NA&gt;\n\n\nsampling_rate\n&lt;NA&gt;\n\n\nfield_type\nTime series file (individual)\n\n\narray\nSingle\n\n\ncohorts\n10K\n\n\ndata_type\ntext\n\n\ndebut\n2018-12-27\n\n\npandas_dtype\nstring\n\n\n\n\n\n\n\n\nml.get('Time series file (individual)', prop='field_type')\n\n\n\n\n\n\n\ntabular_field_name\ncgm/cgm_filename\n\n\n\n\ndataset\ncgm\n\n\nfield_string\nCGM timeseries\n\n\ndescription_string\nName of the file containing the participants' ...\n\n\nparent_dataframe\n&lt;NA&gt;\n\n\nrelative_location\ncgm/cgm.parquet\n\n\nvalue_type\nText\n\n\nunits\n&lt;NA&gt;\n\n\nsampling_rate\n&lt;NA&gt;\n\n\nfield_type\nTime series file (individual)\n\n\narray\nSingle\n\n\ncohorts\n10K\n\n\ndata_type\ntext\n\n\ndebut\n2018-12-27\n\n\npandas_dtype\nstring\n\n\n\n\n\n\n\n\nml.load('Image file (individual)', prop='field_type')\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\nfundus_image_right\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n\n\n1\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n\n\n2\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n\n\n3\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n\n\n4\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n\n\n\n\n\n\n\n\nExample: get all fields that include “mg” in their units\n\n\nml.get('mg', flexible=True, prop='units')\n\n\n\n\n\n\n\ntabular_field_name\ncgm/1st qu_\ncgm/3rd qu_\ncgm/auc\ncgm/ea1c\ncgm/glucose\ncgm/gmi\ncgm/iqr\ncgm/mad\ncgm/mag\ncgm/mage\n...\ncgm/modd\ncgm/range\ncgm/sd\ncgm/sdb\ncgm/sdbdm\ncgm/sddm\ncgm/sdhhmm\ncgm/sdw\ncgm/sdwsh\ndiet_logging/sodium_mg\n\n\n\n\ndataset\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\n...\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ndiet_logging\n\n\nfield_string\n1st quantile\n3rd quantile\nAUC\neA1C\nGlucose\nGMI\nIQR\nMAD\nMAG\nMAGE\n...\nMODD\nRange\nSD\nSDb\nSDbdm\nSDdm\nSDhhmm\nSDw\nSDwsh\nSodium intake per food logged\n\n\ndescription_string\nFirst quantile of all glucose values.\nThird quantile of all glucose values.\nHourly average AUC. This measure integrates, t...\nA linear transformation of the mean glucose va...\ncgm temporal glucose values\nA linear transformation of the mean glucose va...\nInterquartile range (IQR), calculated as the d...\nMedian Absolute Deviation (MAD). This is a mea...\nMean Absolute Glucose (MAG). This is a measure...\nMean Amplitude of Glycemic Excursions (MAGE), ...\n...\nMean difference between glucose values obtaine...\nDifference between the maximum and minimum glu...\nStandard deviation of all glucose values.\nSD between days, within time points. Mean valu...\nSD between days, within time points, corrected...\nHorizontal SD. SD of the mean glucose values, ...\nSD between time points. Standard deviation of ...\nVertical SD within days. Average value of the ...\nSD within series. Taking hour-long intervals t...\nSodium intake per food logged\n\n\nparent_dataframe\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n...\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nrelative_location\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\n...\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ncgm/cgm.parquet\ndiet_logging/diet_logging.parquet\n\n\nvalue_type\nContinuous\nContinuous\nContinuous\nContinuous\nSeries data, continous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\n...\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\n\n\nunits\nmg/dl\nmg/dl\nmg/dl*h\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\n...\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg\n\n\nsampling_rate\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n15min\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n...\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n&lt;NA&gt;\n\n\nfield_type\nData\nData\nData\nData\nContinuous\nData\nData\nData\nData\nData\n...\nData\nData\nData\nData\nData\nData\nData\nData\nData\nData\n\n\narray\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\n...\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n...\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n\n\ndata_type\ntabular\ntabular\ntabular\ntabular\ntime series\ntabular\ntabular\ntabular\ntabular\ntabular\n...\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\nTime Series\n\n\ndebut\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n...\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2019-09-01\n\n\npandas_dtype\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\n...\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\n\n\n\n\n14 rows × 24 columns",
    "crumbs": [
      "Data Loaders",
      "Metadata loader"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pheno-utils",
    "section": "",
    "text": "pheno-utils is a dynamic Python package developed by Pheno.AI, for handling our medical datasets. It simplifies data loading, enables effective merging, and offers intuitive visualization tools.",
    "crumbs": [
      "pheno-utils"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "pheno-utils",
    "section": "Install",
    "text": "Install\npip install pheno_utils",
    "crumbs": [
      "pheno-utils"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "pheno-utils",
    "section": "How to use",
    "text": "How to use\nExamples:\n\ndata = generate_synthetic_data(n=1000)\nhist_ecdf_plots(data=data, col=\"val1\")\n\n\n\n\n\n\n\n\n\nage_refplots = GenderAgeRefPlot(data, \"val1\")\nage_refplots.plot()",
    "crumbs": [
      "pheno-utils"
    ]
  },
  {
    "objectID": "index.html#setting-up-pheno-utils",
    "href": "index.html#setting-up-pheno-utils",
    "title": "pheno-utils",
    "section": "Setting Up pheno-utils",
    "text": "Setting Up pheno-utils\nTo use pheno-utils, you must have a config.json file. This file should be set up according to your filesystem and placed in the ~/.pheno/ directory.\n\nIf You’re Working on TRE\nFor those working in the Trusted Research Environment (TRE), you don’t need to worry about the config.json file. It will be automatically generated for you!\n\n\nIf You’re Working with Phenos’ S3 Bucket\nIf you’re working with Phenos’ S3 bucket, you’ll need to manually create the config.json file. You can do this by running the following Python script:\npython config_setup/create_default_config.py -d s3://datasets_bucket_name\n\n\nIf you are working on local file system\nIf you are working on local file system, you’ll need to manually create the config.json file and locating it under ~/.pheno/ directory. Please use the config_setup/example_config.json as a template for your config.json file.",
    "crumbs": [
      "pheno-utils"
    ]
  },
  {
    "objectID": "date_plots.html",
    "href": "date_plots.html",
    "title": "Dates plots",
    "section": "",
    "text": "source\n\ndates_dist_plot\n\n dates_dist_plot (df:pandas.core.frame.DataFrame, col:str,\n                  sampling_period:str='W-MON', ax:Union[ForwardRef('Extens\n                  ionArray'),numpy.ndarray,ForwardRef('Index'),ForwardRef(\n                  'Series'),list,range,NoneType]=None,\n                  date_col:str='collection_date',\n                  ylim:Optional[Tuple[float,float]]=None,\n                  quantiles:Optional[List[Tuple[float,str]]]=None)\n\n*Creates a scatter plot of data points and their statistics based on a specified sampling period.\nArgs: df (pd.DataFrame): The input DataFrame containing the data. col (str): The column name in the DataFrame to plot. sampling_period (str, optional): The frequency to resample the data. Defaults to ‘W-MON’. ax (Optional[Axes], optional): A matplotlib axes object to plot on. Defaults to None. date_col (str, optional): The name of the date column in the DataFrame. Defaults to ‘collection_date’. ylim (Optional[Tuple[float, float]], optional): A tuple defining the y-axis limits. Defaults to None. quantiles (Optional[List[Tuple[float, str]]], optional): A list of tuples containing quantiles and their labels. Defaults to [(0.1, “10%”), (0.9, “90%”)].*\n\ndata = generate_synthetic_data()\ndata.head()\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2022-12-01\n57.777073\n1\n150.216212\n56.936487\n\n\n1\n2020-07-29\n53.770724\n1\n117.603875\n47.152785\n\n\n2\n2020-09-30\n51.326393\n1\n97.928950\n41.250308\n\n\n3\n2022-05-06\n61.217276\n0\n105.169939\n41.422605\n\n\n4\n2021-06-29\n45.835170\n0\n54.735540\n26.292285\n\n\n\n\n\n\n\n\ndates_dist_plot(data, col=\"val1\", date_col=\"date_of_research_stage\")",
    "crumbs": [
      "Plots",
      "Dates plots"
    ]
  },
  {
    "objectID": "pheno_loader.html",
    "href": "pheno_loader.html",
    "title": "Pheno loader",
    "section": "",
    "text": "source\n\nPhenoLoader\n\n PhenoLoader (dataset:str, base_path:str='nbs/examples/', cohort:str=None,\n              age_sex_dataset:str='events', skip_dfs:List[str]=[],\n              unique_index:bool=False, valid_dates:bool=False,\n              valid_stage:bool=False, flexible_field_search:bool=False,\n              squeeze:bool=False, errors:str='warn',\n              read_parquet_kwargs:Dict[str,Any]={},\n              preferred_language:str='english',\n              keep_undefined_research_stage:bool=False,\n              join_non_overlapping:bool=False)\n\n*Class to load multiple tables from a dataset and allows to easily access their fields.\nArgs:\ndataset (str): The name of the dataset to load.\nbase_path (str, optional): The base path where the data is stored. Defaults to DATASETS_PATH.\ncohort (str, optional): The name of the cohort within the dataset. Defaults to COHORT.\nage_sex_dataset (str, optional): The name of the dataset to use for computing age and sex. Defaults to EVENTS_DATASET.\nskip_dfs (list, optional): A list of tables (or substrings that match to tables) to skip when loading the data. Defaults to [].\nunique_index (bool, optional): Whether to ensure the index of the data is unique. Defaults to False.\nvalid_dates (bool, optional): Whether to ensure that all timestamps in the data are valid dates. Defaults to False.\nvalid_stage (bool, optional): Whether to ensure that all research stages in the data are valid. Defaults to False.\nflexible_field_search (bool, optional): Whether to allow regex field search. Defaults to False.\nkeep_undefined_research_stage (bool, optional): Whether to keep samples with undefined research stage. Defaults to False.\njoin_non_overlapping (bool, optional): Whether to join tables with non-overlapping indices. Defaults to False.\nerrors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n    Possible values are 'raise', 'warn' and 'ignore'. Defaults to ERROR_ACTION.\nAttributes:\ndict (pd.DataFrame): The data dictionary for the dataset, containing information about each field.\ndfs (dict): A dictionary of dataframes, one for each table in the dataset.\nfields (list): A list of all fields in the dataset.\ndataset (str): The name of the dataset being used.\ncohort (str): The name of the cohort being used.\nbase_path (str): The base path where the data is stored.\ndataset_path (str): The full path to the dataset being used.\nage_sex_dataset (str): The name of the dataset being used to compute age and sex.\nskip_dfs (list): A list of tables to skip when loading the data.\nunique_index (bool): Whether to ensure the index of the data is unique.\nvalid_dates (bool): Whether to ensure that all timestamps in the data are valid dates.\nvalid_stage (bool): Whether to ensure that all research stages in the data are valid.\nflexible_field_search (bool): Whether to allow regex field search.\nkeep_undefined_research_stage (bool, optional): Whether to keep samples with undefined research stage.\njoin_non_overlapping (bool): Whether to join tables with non-overlapping indices.\nerrors (str): Whether to raise an error or issue a warning if missing data is encountered.\npreferred_language (str): The preferred language for the questionnaires.*\nUse the dataset name to load the dataset. It may contain multiple tables. Age / sex will be added to the data by default. The default base_path is set to work on the research platform.\n\npl = PhenoLoader('fundus', errors='warn')\npl\n\nPhenoLoader for fundus with\n78 fields\n2 tables: ['fundus', 'age_sex']\n\n\nThe PhenoLoader class contains several usefull attributes\nThe data dictionary of the dataset displays the description of each field.\n\npl.dict.head(3)\n\n\n\n\n\n\n\n\nfield_string\ndescription_string\nparent_dataframe\nrelative_location\nvalue_type\nunits\nsampling_rate\nfield_type\narray\ncohorts\ndata_type\ndebut\npandas_dtype\n\n\ntabular_field_name\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\nFundus image (left)\nFundus image (left)\nNaN\nfundus/fundus.parquet\nText\nNaN\nNaN\nImage file (individual)\nSingle\n10K\nimage\n2021-02-17\nstring\n\n\nfundus_image_right\nFundus image (right)\nFundus image (right)\nNaN\nfundus/fundus.parquet\nText\nNaN\nNaN\nImage file (individual)\nSingle\n10K\nimage\n2021-02-17\nstring\n\n\ncollection_date\nCollection date (YYYY-MM-DD)\nCollection date (YYYY-MM-DD)\nNaN\nfundus/fundus.parquet\nDate\nTime\nNaN\nData\nSingle\n10K\ntabular\n2021-02-17\ndatetime64[ns]\n\n\n\n\n\n\n\n\npl.dfs.keys()\n\ndict_keys(['fundus', 'age_sex'])\n\n\n\nimport pandas as pd\n\n# Example DataFrame with MultiIndex\ndata = {\n    'value': [10, 20, 30, 40]\n}\ntuples = [('A', 'x'), ('A', 'y'), ('B', 'x'), ('B', 'y')]\nindex = pd.MultiIndex.from_tuples(tuples, names=['outer', 'inner'])\ndf = pd.DataFrame(data, index=index)\n\n# Reset the index\ndf_reset = df.reset_index()\n\n# Re-add the desired index levels ('outer', 'inner' in this case) as index\ndf_final = df_reset.set_index(['outer', 'inner'])\n\n\npl.dfs['fundus'].head(3)\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\nfundus_image_right\ncollection_date\nfractal_dimension_left\nfractal_dimension_right\nartery_average_width_left\nartery_average_width_right\nartery_distance_tortuosity_left\nartery_distance_tortuosity_right\nartery_fractal_dimension_left\n...\nvein_fractal_dimension_left\nvein_fractal_dimension_right\nvein_squared_curvature_tortuosity_left\nvein_squared_curvature_tortuosity_right\nvein_tortuosity_density_left\nvein_tortuosity_density_right\nvein_vessel_density_left\nvein_vessel_density_right\nvessel_density_left\nvessel_density_right\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2022-11-16\n1.564989\n1.520885\n18430.284751\n19038.547771\n3.668175\n3.271147\n1.355673\n...\n1.410553\n1.403108\n14.208195\n6.098432\n0.700187\n0.698546\n0.046645\n0.045864\n0.080377\n0.078671\n\n\n1\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2022-06-30\n1.542311\n1.534158\n17315.398780\n19099.489575\n2.095461\n1.634782\n1.368933\n...\n1.387527\n1.332864\n8.999069\n8.702682\n0.740806\n0.708911\n0.037896\n0.046853\n0.074197\n0.064578\n\n\n2\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2021-10-05\n1.482051\n1.545097\n15375.866993\n19855.576862\n2.776472\n2.747015\n1.360404\n...\n1.411881\n1.408791\n13.119227\n9.936669\n0.627281\n0.675100\n0.053022\n0.048063\n0.079515\n0.082102\n\n\n\n\n3 rows × 76 columns\n\n\n\nAll availbale fields (columns) in all tables can be listed.\n\npl.fields[:5]\n\n['artery_average_width_left',\n 'artery_average_width_right',\n 'artery_distance_tortuosity_left',\n 'artery_distance_tortuosity_right',\n 'artery_fractal_dimension_left']\n\n\n\npl['vein_average_width_right']\n\n\n\n\n\n\n\n\n\n\n\nvein_average_width_right\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n18436.428634\n\n\n1\n10k\n00_00_visit\n0\n18888.160314\n\n\n2\n10k\n00_00_visit\n0\n19013.865043\n\n\n3\n10k\n00_00_visit\n0\n18809.012493\n\n\n4\n10k\n00_00_visit\n0\n19428.986690\n\n\n\n\n\n\n\nAccess any of the fields (e.g., vein_average_width_right, age) or indices (e.g., research_stage) from any of the tables via the data loader API.\n\npl[['research_stage', 'vein_average_width_right', 'age', 'sex']]\n\n\n\n\n\n\n\n\n\n\n\nresearch_stage\nvein_average_width_right\nage\nsex\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n00_00_visit\n18436.428634\n43.5\n0\n\n\n1\n10k\n00_00_visit\n0\n00_00_visit\n18888.160314\n53.7\n1\n\n\n2\n10k\n00_00_visit\n0\n00_00_visit\n19013.865043\n26.2\n0\n\n\n3\n10k\n00_00_visit\n0\n00_00_visit\n18809.012493\n44.6\n1\n\n\n4\n10k\n00_00_visit\n0\n00_00_visit\n19428.986690\n50.3\n0\n\n\n\n\n\n\n\nAccess time series or bulk data that is stored separately for each sample via the data loader API. In the following example, the data loader retrieves the relative path of each sample’s bulk file from the main table (where it is stored in the field fundus_image_left), converts it to an absolute path, and loads the file. This is repeated for 2 samples and returned as a list. In the case of parquet DataFrames, there is no need to define the load_func and multiple DFs are concatenated by deafult.\n\npl.dfs['fundus']['fundus_image_left']\n\nparticipant_id  cohort  research_stage  array_index\n0               10k     00_00_visit     0              /path/to/file\n1               10k     00_00_visit     0              /path/to/file\n2               10k     00_00_visit     0              /path/to/file\n3               10k     00_00_visit     0              /path/to/file\n4               10k     00_00_visit     0              /path/to/file\nName: fundus_image_left, dtype: object\n\n\n\npl.load_bulk_data('fundus_image_left', participant_id=[0, 1])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can perform flexible field search (with regex support), when initializing the PhenoLoader as follows:\n\npl = PhenoLoader('fundus', flexible_field_search=True)\n\nFor example, the following command will search for any field starting with “fractal”.\n\npl['^fractal']\n\n\n\n\n\n\n\n\n\n\n\nfractal_dimension_left\nfractal_dimension_right\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n1.564989\n1.520885\n\n\n1\n10k\n00_00_visit\n0\n1.542311\n1.534158\n\n\n2\n10k\n00_00_visit\n0\n1.482051\n1.545097\n\n\n3\n10k\n00_00_visit\n0\n1.548773\n1.539352\n\n\n4\n10k\n00_00_visit\n0\n1.554922\n1.557029\n\n\n\n\n\n\n\nYou can summarize a field or set of fields by the following command\n\npl.describe_field(['fundus_image_right', 'collection_date'])\n\n\n\n\n\n\n\n\nfundus_image_right\ncollection_date\n\n\n\n\nfield_string\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\ndescription_string\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\nparent_dataframe\nNaN\nNaN\n\n\nrelative_location\nfundus/fundus.parquet\nfundus/fundus.parquet\n\n\nvalue_type\nText\nDate\n\n\nunits\nNaN\nTime\n\n\nsampling_rate\nNaN\nNaN\n\n\nfield_type\nImage file (individual)\nData\n\n\narray\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n\n\ndata_type\nimage\ntabular\n\n\ndebut\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nstring\ndatetime64[ns]\n\n\ncount\n5\n5\n\n\nunique\n1\n5\n\n\nmost_frequent\n/path/to/file\nNaN\n\n\nmin\nNaN\n2021-10-05 00:00:00\n\n\nmax\nNaN\n2022-11-16 00:00:00\n\n\nmean\nNaN\nNaN\n\n\nmedian\nNaN\nNaN\n\n\nstd\nNaN\nNaN",
    "crumbs": [
      "Data Loaders",
      "Pheno loader"
    ]
  },
  {
    "objectID": "bulk_data_loader.html",
    "href": "bulk_data_loader.html",
    "title": "Bulk Data Loader",
    "section": "",
    "text": "source\n\nget_function_for_field_type\n\n get_function_for_field_type (field_type)\n\n\nsource\n\n\nload_image\n\n load_image (fname:str)\n\nDisplay a fundus image from an input file path. Args: fname (str): The file path to the fundus image.\n\nsource\n\n\nparse_gtf_attributes\n\n parse_gtf_attributes (attributes_str:str)\n\n*Parse attribute column and return a dictionary.\nParameters: attributes_str (str): The attributes as a semicolon-separated string.\nReturns: dict: A dictionary where the keys are the attribute names and the values are the attribute values.*\n\nsource\n\n\nread_gtf\n\n read_gtf (filename:str)\n\n*Read a GTF file with error handling for lines with too many fields.\nParameters: filename (str): The path to the GTF file.\nReturns: pd.DataFrame: A DataFrame where each row corresponds to a line in the GTF file and each column corresponds to a field or attribute.*\n\nsource\n\n\nshow_fundus\n\n show_fundus (fname:str)"
  },
  {
    "objectID": "cohort_selector.html",
    "href": "cohort_selector.html",
    "title": "Cohort selector",
    "section": "",
    "text": "source\n\nCohortSelector\n\n CohortSelector (base_path:str='nbs/examples/', cohort:str=None,\n                 errors:str='warn', **kwargs)\n\n*Class for selecting a subset of a cohort’s data based on a query.\nArgs:\nbase_path (str, optional): Base path of the datasets. Defaults to DATASETS_PATH.\ncohort (str, optional): Name of the cohort. Defaults to COHORT.\nerrors (str, optional): Error action. Defaults to ERROR_ACTION.\n**kwargs: Additional keyword arguments.\nAttributes:\ncohort (str): Name of the cohort.\nbase_path (str): Base path of the datasets.\nerrors (str): Error action.\nkwargs: Additional keyword arguments.\nml (MetaLoader): MetaLoader object for loading metadata and data.*\n\ncs = CohortSelector()\n\nYou may use the CohortSelector to select participants based on any fields. The selector will return a DataFrame with the selected sub-cohort, along with the fields that were used in the query.\nFor example, the following query selects participants who have moderate obstructive sleep apnea (AHI &gt; 15) based on recordings of at least 4 hours of sleep.\n\ncs.select('15 &lt; ahi &lt; 20 & total_sleep_time &gt; 4*3600')\n\n\n\n\n\n\n\n\n\n\n\nahi\ntotal_sleep_time\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n9\n10k\n02_00_visit\n2\n18.39\n23748.0\n\n\n15\n10k\n00_00_visit\n0\n19.54\n19230.0\n\n\n30\n10k\n00_00_visit\n0\n18.52\n25111.0\n\n\n42\n10k\n00_00_visit\n1\n17.84\n24966.0\n\n\n49\n10k\n02_00_visit\n0\n17.58\n21980.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n902\n10k\n02_00_visit\n2\n19.78\n24162.0\n\n\n914\n10k\n02_00_visit\n2\n17.54\n26479.0\n\n\n936\n10k\n00_00_visit\n1\n17.43\n20865.0\n\n\n941\n10k\n00_00_visit\n0\n17.82\n17606.0\n\n\n965\n10k\n00_00_visit\n2\n15.38\n24390.0\n\n\n\n\n77 rows × 2 columns\n\n\n\nYou may also use the selector to filter on dates. Here we filter on dates of image collection in the fundus imaging dataset.\nIn addition, we may load additional fields that are not part of the query.\n\ncs.select('fundus/collection_date &gt; \"2022-01-01\"', add_fields='fundus_image_left')\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\ncollection_date\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n/path/to/file\n2022-11-16\n\n\n1\n10k\n00_00_visit\n0\n/path/to/file\n2022-06-30\n\n\n3\n10k\n00_00_visit\n0\n/path/to/file\n2022-04-26",
    "crumbs": [
      "Data Loaders",
      "Cohort selector"
    ]
  },
  {
    "objectID": "questionnaire_handler.html",
    "href": "questionnaire_handler.html",
    "title": "Questionnaires Handler",
    "section": "",
    "text": "source\n\ntransform_dataframe\n\n transform_dataframe (df:pandas.core.frame.DataFrame, transform_from:str,\n                      transform_to:str,\n                      dict_df:pandas.core.frame.DataFrame,\n                      mapping_df:pandas.core.frame.DataFrame)\n\n\nsource\n\n\nconvert_codings_to_int\n\n convert_codings_to_int (df:pandas.core.series.Series,\n                         dict_df:pandas.core.frame.DataFrame)\n\n\nsource\n\n\ntransform_answers\n\n transform_answers (tab_field_name:str,\n                    orig_answer:pandas.core.series.Series,\n                    transform_from:str, transform_to:str,\n                    dict_df:pandas.core.frame.DataFrame,\n                    mapping_df:pandas.core.frame.DataFrame)\n\n\nsource\n\n\nreplace_values\n\n replace_values (row:pandas.core.series.Series, mapping_dict:dict)\n\n*Replace values in a row with corresponding values from a mapping dictionary used for categorical multiple questions\nParameters: row (pd.Series): A Pandas Series or a list. Each element of the Series can be an individual value or a list of values. mapping_dict (dict): A dictionary where the keys represent original values and the values represent the values to replace with.\nReturns: pd.Series, list, or float: Transformed row with values replaced according to the mapping dictionary. If the original value is a list or an ndarray, it returns a list. If the original value is NaN, it returns a float (np.nan).*\n\nsource\n\n\ncheck_invalid_values\n\n check_invalid_values (series:pandas.core.series.Series,\n                       mapping_df:pandas.core.frame.DataFrame)\n\n*Check if values in normalized_answer exist in code_df[code_from], excluding np.nan. This check is used to compare the data codings and actual values in the series to make sure there are no invalid values for categoircal single\nArgs: mapping_df (pd.DataFrame): A dataframe whereall the data codings are stored and the values represent the values to replace with. series (pd.Series): The normalized answer series.\nReturns: None: Prints the invalid values found, if any.*\n\nsource\n\n\nflatten_series\n\n flatten_series (series:pandas.core.series.Series)\n\n*Flatten a Pandas Series into a list, where each element of the Series can be an individual value or a list of values.\nParameters: series (pd.Series): A Pandas Series where each element can be a single value or a list of values.\nReturns: list: A flattened list containing all the individual elements from the Series, including those within lists.*\n\nsource\n\n\nnormalize_answers\n\n normalize_answers (orig_answer:pandas.core.series.Series, field_type:str)\n\n*Normalize the answers to be strings. Need to handle nulls which become strings initially and want them to still be na.\nArgs: orig_answer (pd.Series): The original answer series.\nReturns: pd.Series: The normalized answer series.*\n\nsource\n\n\nconvert_to_string\n\n convert_to_string (x)"
  }
]