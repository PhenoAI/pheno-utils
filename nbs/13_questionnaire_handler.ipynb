{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Class for handling questionnaires datasets on the research platform\n",
    "output-file: questionnaires_handler.html\n",
    "title: Questionnaires Handler\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp questionnaires_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "valid_codings = [\"hebrew\", \"english\", \"coding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_string(x):\n",
    "    #function converts a float to a string and for floats of type 1.0 it becomes '1'\n",
    "    return str(int(x)) if isinstance(x, float) and x.is_integer() else str(x)\n",
    "\n",
    "def normalize_answers(orig_answer: pd.Series, field_type: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Normalize the answers to be strings. Need to handle nulls which become strings initially and want them to still be na.\n",
    "\n",
    "    Args:\n",
    "        orig_answer (pd.Series): The original answer series.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: The normalized answer series.\n",
    "    \"\"\"\n",
    "    if field_type == 'Categorical (multiple)':\n",
    "        normalized_answer =  orig_answer.apply(lambda x: [str(i) for i in x] if isinstance(x, np.ndarray) else x)\n",
    "    else:\n",
    "        # Convert the entire series to strings, np.nan will become 'nan'\n",
    "        normalized_answer = orig_answer.astype(str)\n",
    "\n",
    "        # Replace float-like strings with integer-like strings, ignoring 'nan'\n",
    "        normalized_answer = normalized_answer.str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "\n",
    "        # Replace 'nan' with np.nan and similar when dtype is Int64\n",
    "        normalized_answer = normalized_answer.replace(\"nan\", np.nan) \n",
    "        normalized_answer = normalized_answer.replace(\"None\", np.nan) \n",
    "        normalized_answer = normalized_answer.replace(\"<NA>\", np.nan)\n",
    "\n",
    "    return normalized_answer\n",
    "\n",
    "def flatten_series(series: pd.Series) -> list:\n",
    "    \"\"\"\n",
    "    Flatten a Pandas Series into a list, where each element of the Series can be\n",
    "    an individual value or a list of values.\n",
    "\n",
    "    Parameters:\n",
    "    series (pd.Series): A Pandas Series where each element can be a single value\n",
    "                        or a list of values.\n",
    "\n",
    "    Returns:\n",
    "    list: A flattened list containing all the individual elements from the Series,\n",
    "          including those within lists.\n",
    "    \"\"\"\n",
    "    flat_list = []\n",
    "    for item in series:\n",
    "        if isinstance(item, list) or isinstance(item, np.ndarray):\n",
    "            flat_list.extend(item)\n",
    "        elif not pd.isna(item):\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def check_invalid_values(series: pd.Series, mapping_df: pd.DataFrame ):\n",
    "    \"\"\"\n",
    "    Check if values in normalized_answer exist in code_df[code_from], excluding np.nan.\n",
    "    This check is used to compare the data codings and actual values in the series to make sure there are no invalid values for categoircal single \n",
    "\n",
    "    Args:\n",
    "        mapping_df (pd.DataFrame): A dataframe whereall the data codings are stored\n",
    "                         and the values represent the values to replace with.\n",
    "        series (pd.Series): The normalized answer series.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the invalid values found, if any.\n",
    "    \"\"\"\n",
    "    # Check if series contains arrays if it does then it is categorical multiple and we need to flatten the serries first\n",
    "    contains_arrays = series.dropna().apply(lambda x:  isinstance(x, list) or isinstance(x, np.ndarray))\n",
    "    \n",
    "    if True in contains_arrays.unique():\n",
    "        answer_values = set(flatten_series(series))\n",
    "    else:\n",
    "        answer_values = set(series.dropna())\n",
    "    \n",
    "    valid_values = set()\n",
    "    for coding in valid_codings:\n",
    "        valid_values.update(set(mapping_df[coding].unique()))\n",
    "    \n",
    "    invalid_values = answer_values - valid_values\n",
    "    \n",
    "    if invalid_values:\n",
    "        warnings.warn(f\"Invalid values found: {invalid_values}\")\n",
    "\n",
    "\n",
    "def replace_values(row: pd.Series, mapping_dict: dict) -> [pd.Series, list, float]:\n",
    "    \"\"\"\n",
    "    Replace values in a row with corresponding values from a mapping dictionary used for categorical multiple questions\n",
    "    \n",
    "    Parameters:\n",
    "    row (pd.Series): A Pandas Series or a list. Each element of the Series can be\n",
    "                     an individual value or a list of values.\n",
    "    mapping_dict (dict): A dictionary where the keys represent original values\n",
    "                         and the values represent the values to replace with.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series, list, or float: Transformed row with values replaced according\n",
    "                               to the mapping dictionary. If the original value\n",
    "                               is a list or an ndarray, it returns a list. If the\n",
    "                               original value is NaN, it returns a float (np.nan).\n",
    "    \"\"\"\n",
    "    if isinstance(row, np.ndarray) or isinstance(row, list):\n",
    "        row = list(row)  if isinstance(row, np.ndarray) else row\n",
    "        return np.array([mapping_dict.get(item, item) for item in row])\n",
    "    elif pd.isna(row) or pd.isnull(row):\n",
    "        return None\n",
    "    else:\n",
    "        warnings.warn(\"row is not a array or list\")\n",
    "        return row\n",
    "\n",
    "def transform_answers(\n",
    "    tab_field_name: str,\n",
    "    orig_answer: pd.Series,\n",
    "    transform_from: str,\n",
    "    transform_to: str,\n",
    "    dict_df: pd.DataFrame,\n",
    "    mapping_df: pd.DataFrame,\n",
    ") -> pd.Series:\n",
    "    code_from = transform_from.lower()\n",
    "    code_to = transform_to.lower()\n",
    "    assert code_from in valid_codings, f\"transform_from must be one of {valid_codings}\"\n",
    "    assert code_to in valid_codings, f\"transform_to must be one of {valid_codings}\"\n",
    "\n",
    "    #if dictionary index is not tabular field name\n",
    "    if dict_df.index.name != 'tabular_field_name':\n",
    "        dict_df = dict_df.reset_index().set_index('tabular_field_name')\n",
    "    \n",
    "    # converting and formatting data coding values \n",
    "    if isinstance(dict_df.loc[tab_field_name][\"data_coding\"], pd.Series):\n",
    "        if dict_df.loc[tab_field_name][\"data_coding\"].nunique() == 1:\n",
    "            code_string = convert_to_string(dict_df.loc[tab_field_name][\"data_coding\"].iloc[0])\n",
    "        else:\n",
    "            warnings.warn(f\"data_coding has multiple values for tabular field {tab_field_name}, please check and update dictionary\")\n",
    "            return orig_answer\n",
    "    else:\n",
    "        code_string = convert_to_string(dict_df.loc[tab_field_name][\"data_coding\"])\n",
    "    \n",
    "    # Getting the data coding df from the large data coding csv\n",
    "    code_df = mapping_df[mapping_df[\"code_number\"] == code_string].copy()\n",
    "    \n",
    "    # Make sure no leading 0s for coding values\n",
    "    code_df[\"coding\"] =  code_df[\"coding\"].apply(convert_to_string)\n",
    "    cat_ordered = code_df\\\n",
    "        .astype({'coding': 'int'})\\\n",
    "        .sort_values('coding')[code_to]\\\n",
    "        .astype('str')\\\n",
    "        .drop_duplicates()\n",
    "    \n",
    "    mapping_dict = dict(zip(code_df[code_from].astype(str), code_df[code_to]))\n",
    "    \n",
    "  \n",
    "    field_type =  dict_df.loc[tab_field_name]['field_type']\n",
    "    if isinstance(field_type, pd.Series):\n",
    "        if field_type.nunique() == 1:\n",
    "            field_type = field_type.iloc[0]\n",
    "        else:\n",
    "            warnings.warn(f\"tabular field {tab_field_name} is used in 2 columns and have conflicting field types,please check and update dictionary. This field has not be converted.\")\n",
    "            return orig_answer\n",
    "    \n",
    "    if field_type == 'Categorical (multiple)': \n",
    "        normalise_answer = normalize_answers(orig_answer, field_type)\n",
    "        check_invalid_values(normalise_answer , code_df)\n",
    "        transformed_answer = normalise_answer.apply(replace_values, mapping_dict = mapping_dict)\n",
    "    else:\n",
    "        normalized_answer = normalize_answers(orig_answer, field_type)\n",
    "        check_invalid_values(normalized_answer, code_df)\n",
    "        transformed_answer = normalized_answer.replace(mapping_dict)\n",
    "        transformed_answer = pd.Categorical(transformed_answer,\n",
    "            categories=cat_ordered, \n",
    "            ordered=True\n",
    "        )\n",
    "        # We update the dictionary to ensure that the categories are not reset later\n",
    "        dict_df.loc[tab_field_name, 'pandas_dtype'] = 'category_ordered'\n",
    "\n",
    "    return transformed_answer\n",
    "\n",
    "def convert_codings_to_int(df: pd.Series, dict_df: pd.DataFrame) -> pd.Series:\n",
    "    tabular_field_name = df.name\n",
    "    field_array = dict_df.loc[tabular_field_name, 'array']\n",
    "    if isinstance(field_array, pd.Series):\n",
    "        field_array = field_array.iloc[0]\n",
    "    if field_array == 'Multiple':\n",
    "        return df\n",
    "    else: \n",
    "        dict_df.loc[tabular_field_name, 'pandas_dtype'] = 'Int16'\n",
    "        return df.astype('Int16', errors='ignore')\n",
    "\n",
    "def transform_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    transform_from: str,\n",
    "    transform_to: str,\n",
    "    dict_df: pd.DataFrame,\n",
    "    mapping_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    if 'data_coding' not in dict_df.columns:\n",
    "        warnings.warn(\"data_coding column not found in dictionary, skipping transformation\")\n",
    "        return df\n",
    "    # Validate input parameters\n",
    "    if transform_from not in valid_codings or transform_to not in valid_codings:\n",
    "        raise ValueError(f\"transform_from and transform_to must be one of {valid_codings}\")\n",
    "\n",
    "    # Only fields with a code in data_coding property will be transformed\n",
    "    fields_for_translation = dict_df[pd.notna(dict_df.data_coding)].index.intersection(df.columns)\n",
    "    if len(fields_for_translation) == 0: # No fields with data_coding code\n",
    "        return df\n",
    "\n",
    "    transformed_df = df.copy()\n",
    "    for column in fields_for_translation:\n",
    "        data_coding = dict_df.loc[column, 'data_coding']\n",
    "        # Handle the case where data_coding is a Series (multiple entries)\n",
    "        if isinstance(data_coding, pd.Series):\n",
    "            if data_coding.nunique() > 1:\n",
    "                warnings.warn(f\"Multiple different data_coding values found for column {column}. Using first value.\")\n",
    "            data_coding = data_coding.iloc[0]\n",
    "\n",
    "        if pd.isna(data_coding):\n",
    "            continue\n",
    "\n",
    "        if transform_from != transform_to:\n",
    "            transformed_df[column] = transform_answers(\n",
    "                    column,\n",
    "                    transformed_df[column],\n",
    "                    transform_from,\n",
    "                    transform_to,\n",
    "                    dict_df,\n",
    "                    mapping_df\n",
    "                )\n",
    "    \n",
    "        if transform_to == 'coding':\n",
    "            transformed_df[column] = convert_codings_to_int(\n",
    "                transformed_df[column], \n",
    "                dict_df=dict_df\n",
    "            )\n",
    "\n",
    "    return transformed_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
