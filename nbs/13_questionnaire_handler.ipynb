{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Class for handling questionnaires datasets on the research platform\n",
    "output-file: questionnaires_handler.html\n",
    "title: Questionnaires Handler\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp questionnaires_handler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_string(x):\n",
    "    #function converts a float to a string and for floats of type 1.0 it becomes '1'\n",
    "    return str(int(x)) if isinstance(x, float) and x.is_integer() else str(x)\n",
    "\n",
    "def normalize_answers(orig_answer: pd.Series, field_type: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Normalize the answers to be strings. Need to handle nulls which become strings initially and want them to still be na.\n",
    "\n",
    "    Args:\n",
    "        orig_answer (pd.Series): The original answer series.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: The normalized answer series.\n",
    "    \"\"\"\n",
    "    if field_type == 'Categorical (multiple)':\n",
    "        normalized_answer =  orig_answer.apply(lambda x: [str(i) for i in x] if isinstance(x, np.ndarray) else x)\n",
    "    else:\n",
    "        # Convert the entire series to strings, np.nan will become 'nan'\n",
    "        normalized_answer = orig_answer.astype(str)\n",
    "\n",
    "        # Replace float-like strings with integer-like strings, ignoring 'nan'\n",
    "        normalized_answer = normalized_answer.str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "\n",
    "        # Replace 'nan' with np.nan and similar when dtype is Int64\n",
    "        normalized_answer = normalized_answer.replace(\"nan\", np.nan) \n",
    "        normalized_answer = normalized_answer.replace(\"<NA>\", np.nan)\n",
    "\n",
    "    return normalized_answer\n",
    "\n",
    "def flatten_series(series: pd.Series) -> list:\n",
    "    \"\"\"\n",
    "    Flatten a Pandas Series into a list, where each element of the Series can be\n",
    "    an individual value or a list of values.\n",
    "\n",
    "    Parameters:\n",
    "    series (pd.Series): A Pandas Series where each element can be a single value\n",
    "                        or a list of values.\n",
    "\n",
    "    Returns:\n",
    "    list: A flattened list containing all the individual elements from the Series,\n",
    "          including those within lists.\n",
    "    \"\"\"\n",
    "    flat_list = []\n",
    "    for item in series:\n",
    "        if isinstance(item, list) or isinstance(item, np.ndarray):\n",
    "            flat_list.extend(item)\n",
    "        elif not pd.isna(item):\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def check_invalid_values(series: pd.Series, mapping_dict: dict ):\n",
    "    \"\"\"\n",
    "    Check if values in normalized_answer exist in code_df[code_from], excluding np.nan.\n",
    "    This check is used to compare the data codings and actual values in the series to make sure there are no invalid values for categoircal single \n",
    "\n",
    "    Args:\n",
    "        mapping_dict (dict): A dictionary where the keys represent original values\n",
    "                         and the values represent the values to replace with.\n",
    "        series (pd.Series): The normalized answer series.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the invalid values found, if any.\n",
    "    \"\"\"\n",
    "    # Check if series contains arrays if it does then it is categorical multiple and we need to flatten the serries first\n",
    "    contains_arrays = series.dropna().apply(lambda x:  isinstance(x, list) or isinstance(x, np.ndarray))\n",
    "    \n",
    "    if True in contains_arrays.unique():\n",
    "        answer_values = set(flatten_series(series))\n",
    "    else:\n",
    "        answer_values = set(series.dropna())\n",
    "    \n",
    "    valid_values = set(mapping_dict.keys())\n",
    "    invalid_values = answer_values - valid_values\n",
    "\n",
    "    if invalid_values:\n",
    "        warnings.warn(f\"Invalid values found: {invalid_values}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def replace_values(row: pd.Series, mapping_dict: dict) -> [pd.Series, list, float]:\n",
    "    \"\"\"\n",
    "    Replace values in a row with corresponding values from a mapping dictionary used for categpoical multiple questions\n",
    "    \n",
    "    Parameters:\n",
    "    row (pd.Series): A Pandas Series or a list. Each element of the Series can be\n",
    "                     an individual value or a list of values.\n",
    "    mapping_dict (dict): A dictionary where the keys represent original values\n",
    "                         and the values represent the values to replace with.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series, list, or float: Transformed row with values replaced according\n",
    "                               to the mapping dictionary. If the original value\n",
    "                               is a list or an ndarray, it returns a list. If the\n",
    "                               original value is NaN, it returns a float (np.nan).\n",
    "    \"\"\"\n",
    "    if isinstance(row, np.ndarray) or isinstance(row, list):\n",
    "        row = list(row)  if isinstance(row, np.ndarray) else row\n",
    "        return np.array([mapping_dict.get(item, item) for item in row])\n",
    "    elif pd.isna(row) or pd.isnull(row):\n",
    "        return None\n",
    "    else:\n",
    "        warnings.warn(\"warning: row is not a array or list\")\n",
    "        return row\n",
    "\n",
    "def transform_answers(\n",
    "    tab_field_name: str,\n",
    "    orig_answer: pd.Series,\n",
    "    transform_from: str,\n",
    "    transform_to: str,\n",
    "    dict_df: pd.DataFrame,\n",
    "    mapping_df: pd.DataFrame,\n",
    ") -> pd.Series:\n",
    "    code_from = transform_from.lower()\n",
    "    code_to = transform_to.lower()\n",
    "    assert code_from in [\"hebrew\", \"english\", \"coding\"], \"transform_from must be one of 'hebrew', 'english', 'coding'\"\n",
    "    assert code_to in [\"hebrew\", \"english\", \"coding\"], \"transform_to must be one of 'hebrew', 'english', 'coding'\"\n",
    "\n",
    "    #if dictionary index is not tabular field name\n",
    "    if dict_df.index.name != 'tabular_field_name':\n",
    "        dict_df = dict_df.reset_index().set_index('tabular_field_name')\n",
    "    \n",
    "    # converting and formatting data coding values \n",
    "    if isinstance(dict_df.loc[tab_field_name][\"data_coding\"], pd.Series):\n",
    "        if dict_df.loc[tab_field_name][\"data_coding\"].nunique() == 1:\n",
    "            code_string = convert_to_string(dict_df.loc[tab_field_name][\"data_coding\"].iloc[0])\n",
    "        else:\n",
    "            warnings.warn(\"data_coding has multiple values for tabular field {tab_field_name}, please check and update dictionary\")\n",
    "            return orig_answer\n",
    "    else:\n",
    "        code_string = convert_to_string(dict_df.loc[tab_field_name][\"data_coding\"])\n",
    "    \n",
    "    #getting the data coding df from the large data coding csv\n",
    "    code_df = mapping_df[mapping_df[\"code_number\"] == code_string].copy()\n",
    "    \n",
    "    #Make sure no leading 0s for coding values\n",
    "    code_df[\"coding\"] =  code_df[\"coding\"].apply(convert_to_string)\n",
    "    \n",
    "    mapping_dict = dict(zip(code_df[code_from].astype(str), code_df[code_to]))\n",
    "    \n",
    "  \n",
    "  #adding fail safe incase older dictionaries don't have field type : TODO potentaily remove once older dictionaires are updated\n",
    "    if 'field_type' in dict_df.columns:\n",
    "        field_type =  dict_df.loc[tab_field_name]['field_type']\n",
    "        if isinstance(field_type, pd.Series):\n",
    "            if field_type.nunique() == 1:\n",
    "                field_type = field_type.iloc[0]\n",
    "            else:\n",
    "                warnings.warn(f\"tabular field {tab_field_name} is used in 2 columns and have conflicting field types,please check and update dictionary. This field has not be converted.\")\n",
    "                return orig_answer\n",
    "        \n",
    "        if field_type == 'Categorical (multiple)': \n",
    "            normalise_answer = normalize_answers(orig_answer, field_type)\n",
    "            check_invalid_values( normalise_answer , mapping_dict)\n",
    "            transformed_answer = normalise_answer.apply(replace_values, mapping_dict = mapping_dict)\n",
    "        else:\n",
    "            #if categorical single\n",
    "            normalized_answer = normalize_answers(orig_answer, field_type)\n",
    "            check_invalid_values(normalized_answer, mapping_dict)\n",
    "            transformed_answer = normalized_answer.replace(mapping_dict)\n",
    "            transformed_answer = transformed_answer.astype(\"category\")\n",
    "\n",
    "        return transformed_answer\n",
    "    else:\n",
    "        return orig_answer\n",
    "\n",
    "\n",
    "def transform_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    transform_from: str,\n",
    "    transform_to: str,\n",
    "    dict_df: pd.DataFrame,\n",
    "    mapping_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    if 'data_coding' not in dict_df.columns or transform_from == transform_to:\n",
    "        return df\n",
    "    \n",
    "    fields_for_translation = dict_df[pd.notna(dict_df.data_coding)].index.intersection(df.columns)\n",
    "    if len(fields_for_translation) == 0:\n",
    "        return df\n",
    "    transformed_df = df.copy()\n",
    "    for column in fields_for_translation:\n",
    "        data_coding = dict_df.loc[column, 'data_coding']\n",
    "        # Handle the case where data_coding is a Series (multiple entries)\n",
    "        if isinstance(data_coding, pd.Series):\n",
    "            data_coding = data_coding.iloc[0]\n",
    "        \n",
    "        if pd.notna(data_coding):\n",
    "            transformed_df[column] = transform_answers(\n",
    "                    column,\n",
    "                    transformed_df[column],\n",
    "                    transform_from,\n",
    "                    transform_to,\n",
    "                    dict_df,\n",
    "                    mapping_df\n",
    "                )\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
