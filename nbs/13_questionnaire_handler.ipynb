{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Class for handling questionnaires datasets on the research platform\n",
    "output-file: questionnaires_handler.html\n",
    "title: Questionnaires Handler\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp questionnaires_handler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_to_string(x):\n",
    "    return str(int(x)) if isinstance(x, float) and x.is_integer() else str(x)\n",
    "\n",
    "def normalize_answers(orig_answer: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Normalize the answers from string.\n",
    "\n",
    "    Args:\n",
    "        orig_answer (pd.Series): The original answer series.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: The normalized answer series.\n",
    "    \"\"\"\n",
    "    # Convert the entire series to strings, np.nan will become 'nan'\n",
    "    normalized_answer = orig_answer.astype(str)\n",
    "\n",
    "    # Replace float-like strings with integer-like strings, ignoring 'nan'\n",
    "    normalized_answer = normalized_answer.str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "    normalized_answer = normalized_answer.replace(\"nan\", np.nan) #check\n",
    "    normalized_answer = normalized_answer.replace(\"<NA>\", np.nan)\n",
    "\n",
    "    return normalized_answer\n",
    "\n",
    "def check_invalid_values(code_df, code_from, normalized_answer):\n",
    "    \"\"\"\n",
    "    Check if values in normalized_answer exist in code_df[code_from], excluding np.nan.\n",
    "\n",
    "    Args:\n",
    "        code_df (pd.DataFrame): The DataFrame containing the code mappings.\n",
    "        code_from (str): The column name to check in code_df.\n",
    "        normalized_answer (pd.Series): The normalized answer series.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints the invalid values found, if any.\n",
    "    \"\"\"\n",
    "    # Check if values in normalized_answer exist in code_df[code_from], excluding np.nan\n",
    "    valid_values = set(code_df[code_from].astype(str))\n",
    "    answer_values = set(normalized_answer.dropna())\n",
    "    invalid_values = answer_values - valid_values\n",
    "\n",
    "    if invalid_values:\n",
    "        warnings.warn(f\"Invalid values found: {invalid_values}\")\n",
    "\n",
    "def flatten_series(series: pd.Series) -> list:\n",
    "    \"\"\"\n",
    "    Flatten a Pandas Series into a list, where each element of the Series can be\n",
    "    an individual value or a list of values.\n",
    "\n",
    "    Parameters:\n",
    "    series (pd.Series): A Pandas Series where each element can be a single value\n",
    "                        or a list of values.\n",
    "\n",
    "    Returns:\n",
    "    list: A flattened list containing all the individual elements from the Series,\n",
    "          including those within lists.\n",
    "    \"\"\"\n",
    "    flat_list = []\n",
    "    for item in series:\n",
    "        if isinstance(item, list) or isinstance(item, np.ndarray):\n",
    "            flat_list.extend(item)\n",
    "        elif not pd.isna(item):\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "def check_values(series: pd.Series, mapping_dict: dict) -> None:\n",
    "    \"\"\"\n",
    "    Check if all values in a Series have corresponding mappings in a dictionary.\n",
    "    Raise a warning if any value in the Series doesn't have a mapping.\n",
    "\n",
    "    Parameters:\n",
    "    series (pd.Series): A Pandas Series to check.\n",
    "    mapping_dict (dict): A dictionary where the keys represent the values to be\n",
    "                         checked against the Series.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return anything. It raises warnings if any\n",
    "          mismatch is found between the Series values and dictionary keys.\n",
    "    \"\"\"\n",
    "    unique_values = set(flatten_series(series))\n",
    "    missing_values = unique_values - set(mapping_dict.keys())\n",
    "    if missing_values:\n",
    "        warnings.warn(f\"Warning: Missing mappings for values {missing_values} for tabular field {series.name}\")\n",
    "\n",
    "\n",
    "def replace_values(row: pd.Series, mapping_dict: dict) -> [pd.Series, list, float]:\n",
    "    \"\"\"\n",
    "    Replace values in a row with corresponding values from a mapping dictionary used for categpoical multiple questions\n",
    "    \n",
    "    Parameters:\n",
    "    row (pd.Series): A Pandas Series or a list. Each element of the Series can be\n",
    "                     an individual value or a list of values.\n",
    "    mapping_dict (dict): A dictionary where the keys represent original values\n",
    "                         and the values represent the values to replace with.\n",
    "\n",
    "    Returns:\n",
    "    pd.Series, list, or float: Transformed row with values replaced according\n",
    "                               to the mapping dictionary. If the original value\n",
    "                               is a list or an ndarray, it returns a list. If the\n",
    "                               original value is NaN, it returns a float (np.nan).\n",
    "    \"\"\"\n",
    "    if isinstance(row, list) or isinstance(row, np.ndarray):\n",
    "        row = list(row) if isinstance(row, np.ndarray) else row\n",
    "        return [mapping_dict.get(item, item) for item in row]\n",
    "    elif pd.isna(row):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return mapping_dict.get(row, row)\n",
    "\n",
    "def transform_answers(\n",
    "    tab_field_name: str,\n",
    "    orig_answer: pd.Series,\n",
    "    transform_from: str,\n",
    "    transform_to: str,\n",
    "    dict_df: pd.DataFrame,\n",
    "    mapping_df: pd.DataFrame,\n",
    ") -> pd.Series:\n",
    "    code_from = transform_from.lower()\n",
    "    code_to = transform_to.lower()\n",
    "    assert code_from in [\"hebrew\", \"english\", \"coding\"], \"transform_from must be one of 'hebrew', 'english', 'coding'\"\n",
    "    assert code_to in [\"hebrew\", \"english\", \"coding\"], \"transform_to must be one of 'hebrew', 'english', 'coding'\"\n",
    "\n",
    "    #if dictionary index is not tabular field name\n",
    "    if dict_df.index.name != 'tabular_field_name':\n",
    "        dict_df = dict_df.reset_index().set_index('tabular_field_name')\n",
    "    \n",
    "    # converting and formatting data coding values \n",
    "    if isinstance(dict_df.loc[tab_field_name][\"data_coding\"], pd.Series):\n",
    "        code_string = convert_to_string(dict_df.loc[tab_field_name][\"data_coding\"].iloc[0])\n",
    "    else:\n",
    "        code_string = convert_to_string(dict_df.loc[tab_field_name][\"data_coding\"])\n",
    "    \n",
    "    #getting the data coding df from the large data coding csv\n",
    "    code_df = mapping_df[mapping_df[\"code_number\"] == code_string].copy()\n",
    "    #Make sure no leading 0s for coding values\n",
    "    code_df[\"coding\"] = code_df[\"coding\"].astype(int).astype(str)\n",
    "    coding = dict(zip(code_df[code_from].astype(str), code_df[code_to]))\n",
    "    \n",
    "    \n",
    "    field_type =  dict_df.loc[tab_field_name]['field_type']\n",
    "    #if tab field is in 2 features sets it will be a series so just check the first case\n",
    "    if isinstance(field_type, pd.Series) and field_type.iloc[0].strip() == 'Categorical (multiple)' or isinstance(field_type, str) and field_type.strip() == 'Categorical (multiple)':\n",
    "          # Convert dictionary keys to integers\n",
    "        mapping_dict = {int(k): v for k, v in coding.items()}\n",
    "        check_values( orig_answer , mapping_dict)\n",
    "        transformed_answer = orig_answer.apply(replace_values, mapping_dict = mapping_dict)\n",
    "    else:\n",
    "        #if categorical single\n",
    "        normalized_answer = normalize_answers(orig_answer)\n",
    "        check_invalid_values(code_df, code_from, normalized_answer)\n",
    "        transformed_answer = normalized_answer.replace(coding)\n",
    "        transformed_answer = transformed_answer.astype(\"category\")\n",
    "\n",
    "    return transformed_answer\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "def transform_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    transform_from: str,\n",
    "    transform_to: str,\n",
    "    dict_df: pd.DataFrame,\n",
    "    mapping_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    if 'data_coding' not in dict_df.columns or transform_from == transform_to:\n",
    "        return df\n",
    "    \n",
    "    fields_for_translation = dict_df[pd.notna(dict_df.data_coding)].index.intersection(df.columns)\n",
    "    if len(fields_for_translation) == 0:\n",
    "        return df\n",
    "    transformed_df = df.copy()\n",
    "    for column in fields_for_translation:\n",
    "        print(column)\n",
    "        try: \n",
    "            data_coding = dict_df.loc[column, 'data_coding']\n",
    "        except Exception as e:\n",
    "            warnings.warn(f'Could not find data_coding for column {column}')\n",
    "            continue\n",
    "        # Handle the case where data_coding is a Series (multiple entries)\n",
    "        if isinstance(data_coding, pd.Series):\n",
    "            # Proceed only if all data_codings are consistent\n",
    "            if data_coding.nunique() == 1 and pd.notna(data_coding.iloc[0]):\n",
    "                transformed_df[column] = transform_answers(\n",
    "                    column,\n",
    "                    transformed_df[column],\n",
    "                    transform_from,\n",
    "                    transform_to,\n",
    "                    dict_df,\n",
    "                    mapping_df\n",
    "                )\n",
    "        else:  # Single value for data_coding\n",
    "            if pd.notna(data_coding):\n",
    "                transformed_df[column] = transform_answers(\n",
    "                    column,\n",
    "                    transformed_df[column],\n",
    "                    transform_from,\n",
    "                    transform_to,\n",
    "                    dict_df,\n",
    "                    mapping_df\n",
    "                )\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
